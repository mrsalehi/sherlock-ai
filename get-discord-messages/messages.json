[{"id":"1117168453380477039","type":0,"content":"How can I stream response in    llm.HuggingFaceEndpoint? (https://github.com/hwchase17/langchain/blob/62ec10a7f5110b3b264c3851fc98d784848f7259/langchain/llms/huggingface_endpoint.py#L15)","channel_id":"1038097349660135474","author":{"id":"888852829060612106","username":"harsh1729","global_name":null,"avatar":null,"discriminator":"5323","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchain/blob/62ec10a7f5110b3b264c3851fc98d784848f7259/langchain/llms/huggingface_endpoint.py","title":"langchain/huggingface_endpoint.py at 62ec10a7f5110b3b264c3851fc98d7...","description":"⚡ Building applications with LLMs through composability ⚡ - langchain/huggingface_endpoint.py at 62ec10a7f5110b3b264c3851fc98d784848f7259 · hwchase17/langchain","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/60d35735773ff9828d26131ae9865351df6da39b2d1b7cdd5ee2cbd8543c53a3/hwchase17/langchain","proxy_url":"https://images-ext-1.discordapp.net/external/zrfVE7la_5a7MdBdDMI7j5XKsfSD7X5daJ1Y2l-FBLY/https/opengraph.githubassets.com/60d35735773ff9828d26131ae9865351df6da39b2d1b7cdd5ee2cbd8543c53a3/hwchase17/langchain","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T19:08:35.272000+00:00","edited_timestamp":"2023-06-10T19:11:28.017000+00:00","flags":0,"components":[]},{"id":"1117144260806983760","type":0,"content":"Are there any good references or resources related to information retrieval with hybrid search?","channel_id":"1038097349660135474","author":{"id":"754329612309364836","username":"Swastik K","global_name":null,"avatar":"5536f126bd58d6edfd7e0a0894cf22e7","discriminator":"4243","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T17:32:27.313000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117142910559866930","type":0,"content":"```from llama_index import VectorStoreIndex, SimpleDirectoryReader\nimport os\nimport openai\nfrom langchain.agents import Tool\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.utilities import SerpAPIWrapper\nfrom langchain.agents import initialize_agent\nfrom langchain.agents import AgentType\n\nos.environ[\"OPENAI_API_KEY\"] = \"key\"\nopenai.api_key = \"key\"\n\n\ndocuments = SimpleDirectoryReader('./dataf').load_data()\nindex = VectorStoreIndex.from_documents(documents=documents)\n\ntools = [\n    Tool(\n        name = \"mytool\",\n        func=lambda q: str(index.as_query_engine().query(q)),\n        description=\"mytool\",\n        verbose=True,\n    ),\n]\n\n# set Logging to DEBUG for more detailed outputs\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\nllm = ChatOpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\")\nagent_executor = initialize_agent(tools, llm, agent=\"chat-conversational-react-description\" , memory=memory, verbose=True)\n\n\nwhile True:\n    quest = input(\"Quest: \")\n    print(agent_executor.run(input=quest))\n\n\n```\nhow can i make my tool have a higher priority than the knowledge of chatgpt. e.g. if in my documents it says chatgpt myai then it should be given like that when I ask who are you","channel_id":"1038097349660135474","author":{"id":"796698806393634817","username":"LeiCraft_","global_name":"LeiCraft_","avatar":"86a4fd0b47192da2c24268d9ddd060d4","discriminator":"1192","public_flags":4194432,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T17:27:05.389000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117141003002990642","type":0,"content":"Hi guys, does anyone had trouble installing jq on python for windows? I'm trying to install it so I can use the json loader","channel_id":"1038097349660135474","author":{"id":"539761137084923916","username":"Flying_jabutA","global_name":null,"avatar":null,"discriminator":"7841","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T17:19:30.592000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117101440532484178","type":0,"content":"Actually I see there is a js support. I will move this there.","channel_id":"1038097349660135474","author":{"id":"285227029060780032","username":"Kyle Parkin","global_name":null,"avatar":"c65438c7a228f4a58581d02533d21534","discriminator":"2916","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T14:42:18.164000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117101331858063460","type":0,"content":"The error I keep gettting is \n```\nquery.ts:126 TypeError: Cannot read properties of undefined (reading 'forEach')\n    at RefineDocumentsChain._constructInitialInputs (combine_docs_chain.js:294:1)\n    at RefineDocumentsChain._call (combine_docs_chain.js:330:1)\n    at RefineDocumentsChain.call (base.js:65:1)\n    at async query (query.ts:114:1)\n    at async handleAskAIButton (FullPageAskAI.tsx:67:1)\n```\nI am thinking it has to do with the documentPrompt not being implemented. My docs are an array of strings. I am not sure if they should be strings or an array of objects like the way createDocuments out puts them.\n\nAny way any support you guys have would be amazing","channel_id":"1038097349660135474","author":{"id":"285227029060780032","username":"Kyle Parkin","global_name":null,"avatar":"c65438c7a228f4a58581d02533d21534","discriminator":"2916","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T14:41:52.254000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117100503491432568","type":0,"content":"So I have trying to implement RefineDocumentsChain() for the past couple of hours and I am struggling to understand what goes in the document prompt. \n\n```js\n\nconst chain = new RefineDocumentsChain({\n        llmChain: llmChain,\n        refineLLMChain: llmChain,\n        documentPrompt: {}\n      });\n\nconst res = await chain.call({\n        input_documents: docs, \n        question: queryQuestion,\n        });\n\n```\n\nAny help would be much appreciated. I am stuck and not getting much out of the docs for implementing this.","channel_id":"1038097349660135474","author":{"id":"285227029060780032","username":"Kyle Parkin","global_name":null,"avatar":"c65438c7a228f4a58581d02533d21534","discriminator":"2916","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T14:38:34.756000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117083080491024414","type":19,"content":"I actually figured this out by adding this code:\n    // Add custom metadata to each rawDoc\n    for (const rawDoc of rawDocs) {\n      rawDoc.metadata.custom = 'xxxxx';  // Your custom metadata here\n    }","channel_id":"1038097349660135474","author":{"id":"1030487171586596934","username":"topflrbss","global_name":null,"avatar":null,"discriminator":"8987","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T13:29:20.789000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1117078246329167912"},"referenced_message":{"id":"1117078246329167912","type":0,"content":"I am trying to upload additional metadata such as \"textName\" when I uplaod my documents to Supabase. Does anyknow know how to add specific metadata?\n`    // Load PDF files from the specified directory\n    const directoryLoader = new DirectoryLoader(filePath, {\n      '.pdf': (path) => new PDFLoader(path),\n      '.docx': (path) => new DocxLoader(path),\n      '.txt': (path) => new TextLoader(path),\n    });\n\n\n    const rawDocs = await directoryLoader.load();\n\n\n    // Split the PDF documents into smaller chunks\n    const textSplitter = new RecursiveCharacterTextSplitter({\n      chunkSize: 1000,\n      chunkOverlap: 200,\n    });\n\n    const docs = await textSplitter.splitDocuments(rawDocs);\n\n    // OpenAI embeddings for the document chunks\n    const embeddings = new OpenAIEmbeddings({stripNewLines: true});\n\n    // Store the document chunks in Supabase with their embeddings\n    await SupabaseVectorStore.fromDocuments(docs, embeddings, {\n      client: supabase,\n      tableName: \"documents\",\n      queryName: 'match_documents',\n    });`","channel_id":"1038097349660135474","author":{"id":"1030487171586596934","username":"topflrbss","global_name":null,"avatar":null,"discriminator":"8987","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T13:10:08.235000+00:00","edited_timestamp":"2023-06-10T13:10:37.801000+00:00","flags":0,"components":[]}},{"id":"1117078246329167912","type":0,"content":"I am trying to upload additional metadata such as \"textName\" when I uplaod my documents to Supabase. Does anyknow know how to add specific metadata?\n`    // Load PDF files from the specified directory\n    const directoryLoader = new DirectoryLoader(filePath, {\n      '.pdf': (path) => new PDFLoader(path),\n      '.docx': (path) => new DocxLoader(path),\n      '.txt': (path) => new TextLoader(path),\n    });\n\n\n    const rawDocs = await directoryLoader.load();\n\n\n    // Split the PDF documents into smaller chunks\n    const textSplitter = new RecursiveCharacterTextSplitter({\n      chunkSize: 1000,\n      chunkOverlap: 200,\n    });\n\n    const docs = await textSplitter.splitDocuments(rawDocs);\n\n    // OpenAI embeddings for the document chunks\n    const embeddings = new OpenAIEmbeddings({stripNewLines: true});\n\n    // Store the document chunks in Supabase with their embeddings\n    await SupabaseVectorStore.fromDocuments(docs, embeddings, {\n      client: supabase,\n      tableName: \"documents\",\n      queryName: 'match_documents',\n    });`","channel_id":"1038097349660135474","author":{"id":"1030487171586596934","username":"topflrbss","global_name":null,"avatar":null,"discriminator":"8987","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T13:10:08.235000+00:00","edited_timestamp":"2023-06-10T13:10:37.801000+00:00","flags":0,"components":[]},{"id":"1117047287802245121","type":0,"content":"maybe i can make a PR to the canonical one since they're doing a bunch of little mistakes","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:07:07.147000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117047201181478942","type":0,"content":"thank you!","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:06:46.495000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117047184005791764","type":0,"content":"ok will push","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:06:42.400000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117046985007046657","type":0,"content":"woot","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1117046985048981546","filename":"image.png","size":13997,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1117046985048981546/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1117046985048981546/image.png","width":400,"height":101,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:05:54.955000+00:00","edited_timestamp":null,"flags":0,"components":[],"reactions":[{"emoji":{"id":null,"name":"🔥"},"count":1,"count_details":{"burst":1,"normal":0},"burst_colors":["#4c704f","#f08d0e","#f0b74a","#f0941d","#f09a2c","#f0a13b","#f0b23b"],"me_burst":false,"me":false,"burst_count":1}]},{"id":"1117046904686133259","type":19,"content":">18","channel_id":"1038097349660135474","author":{"id":"547073796738252801","username":"godlike","global_name":null,"avatar":null,"discriminator":"9602","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"168844554286399488","username":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"fotoflo","avatar_decoration":null,"display_name":"fotoflo","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:05:35.805000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1117046850080481292"},"referenced_message":{"id":"1117046850080481292","type":0,"content":"is there a suggested version of nodejs btw? the starter package i used didnt specify an engine","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:05:22.786000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1117046850080481292","type":0,"content":"is there a suggested version of nodejs btw? the starter package i used didnt specify an engine","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:05:22.786000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117046711567786014","type":0,"content":"thank you <@547073796738252801>","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"547073796738252801","username":"godlike","avatar":null,"discriminator":"9602","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:04:49.762000+00:00","edited_timestamp":null,"flags":0,"components":[],"reactions":[{"emoji":{"id":null,"name":"👍"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}]},{"id":"1117046694400507987","type":0,"content":"there was an error, i think i fixed it - now its a timeout 🙂 so i think im on my way!","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:04:45.669000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117046359531458601","type":0,"content":"but","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:03:25.830000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117046354716409867","type":0,"content":"well tit runs now!","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:03:24.682000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117046325813461023","type":0,"content":"ok","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:03:17.791000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117046262160687104","type":0,"content":"i'm not aware of it. you can create one of yours","channel_id":"1038097349660135474","author":{"id":"547073796738252801","username":"godlike","global_name":null,"avatar":null,"discriminator":"9602","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:03:02.615000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117046162034266132","type":0,"content":"?","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:02:38.743000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117046158553006091","type":0,"content":"is there a newer \"starter project\" <@547073796738252801>","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"547073796738252801","username":"godlike","avatar":null,"discriminator":"9602","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:02:37.913000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117045679479599124","type":0,"content":"thanks will give it a shot","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:00:43.693000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117045593588637757","type":19,"content":"looks like you're using a old version, you can try updating it to 0.0.90 or 0.0.92","channel_id":"1038097349660135474","author":{"id":"547073796738252801","username":"godlike","global_name":null,"avatar":null,"discriminator":"9602","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"168844554286399488","username":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"fotoflo","avatar_decoration":null,"display_name":"fotoflo","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T11:00:23.215000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1117044734079279184"},"referenced_message":{"id":"1117044734079279184","type":0,"content":"","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1117044733844406302","filename":"image.png","size":22537,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1117044733844406302/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1117044733844406302/image.png","width":462,"height":177,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:56:58.292000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1117045213412728842","type":0,"content":"it kept giving me new transform patterns and and things","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:58:52.574000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117045169481592913","type":0,"content":"(i also asked chatgpt4 for a number of suggestions but didnt get anywhere)","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:58:42.100000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117045108953583617","type":0,"content":"<@547073796738252801> does that help?","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"547073796738252801","username":"godlike","avatar":null,"discriminator":"9602","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:58:27.669000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117045025973481533","type":0,"content":"i just took the default jest config ```js\nexport default {\n  roots: [\"<rootDir>/src\"],\n  testMatch: [\n    \"**/__tests__/**/*.+(ts|tsx|js)\",\n    \"**/?(*.)+(spec|test).+(ts|tsx|js)\",\n  ],\n  transform: {\n    \"^.+\\\\.(ts|tsx)$\": \"ts-jest\",\n  },\n};\n```","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:58:07.885000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117044923926056960","type":0,"content":"but jest wont compile it i think, so im assuming its a jestconfig issue","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:57:43.555000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117044879936213042","type":0,"content":"the application runs on npm start","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:57:33.067000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117044820389666816","type":0,"content":"looks like it's installed","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:57:18.870000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117044734079279184","type":0,"content":"","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1117044733844406302","filename":"image.png","size":22537,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1117044733844406302/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1117044733844406302/image.png","width":462,"height":177,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:56:58.292000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117044374509998170","type":0,"content":"also have you installed all the required packages?","channel_id":"1038097349660135474","author":{"id":"547073796738252801","username":"godlike","global_name":null,"avatar":null,"discriminator":"9602","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:55:32.564000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117044317761048627","type":19,"content":"what version of langchain are you using?","channel_id":"1038097349660135474","author":{"id":"547073796738252801","username":"godlike","global_name":null,"avatar":null,"discriminator":"9602","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"168844554286399488","username":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"fotoflo","avatar_decoration":null,"display_name":"fotoflo","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:55:19.034000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1117044186278023238"},"referenced_message":{"id":"1117044186278023238","type":0,"content":"<@547073796738252801> Thank you.   i still get\n\n  ● Test suite failed to run\n\n    Cannot find module 'langchain' from 'src/index.ts'\n\n    Require stack:\n      src/index.ts\n      src/__test__/index.test.ts\n\n      1 | import * as dotenv from \"dotenv\";\n> 2 | import { OpenAI } from \"langchain\";","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"547073796738252801","username":"godlike","avatar":null,"discriminator":"9602","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:54:47.686000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1117044186278023238","type":0,"content":"<@547073796738252801> Thank you.   i still get\n\n  ● Test suite failed to run\n\n    Cannot find module 'langchain' from 'src/index.ts'\n\n    Require stack:\n      src/index.ts\n      src/__test__/index.test.ts\n\n      1 | import * as dotenv from \"dotenv\";\n> 2 | import { OpenAI } from \"langchain\";","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"547073796738252801","username":"godlike","avatar":null,"discriminator":"9602","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:54:47.686000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117043165778677842","type":0,"content":"Is there a best practice to de-duplicate overlapping chunks after retrieval from the vector store prior to sending them a context to the LLM? I did not find a way to make the Splitters return the start and end positions of the chunks in respect to the full document. If found that you can search for the chunk content in the whole document to get the start position and use the length to calculate the end position but this is not 100% reliable as especially a smaller chunk could match multiple times.","channel_id":"1038097349660135474","author":{"id":"1105415827597041777","username":"altampy55","global_name":null,"avatar":null,"discriminator":"9464","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:50:44.380000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117043003467517973","type":19,"content":"try \n`import { OpenAI } from \"langchain\";`","channel_id":"1038097349660135474","author":{"id":"547073796738252801","username":"godlike","global_name":null,"avatar":null,"discriminator":"9602","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"168844554286399488","username":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"fotoflo","avatar_decoration":null,"display_name":"fotoflo","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:50:05.682000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1117036841720348773"},"referenced_message":{"id":"1117036841720348773","type":0,"content":"(i just took the ts starter and added jest)","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:25:36.607000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1117036841720348773","type":0,"content":"(i just took the ts starter and added jest)","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:25:36.607000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117035503678660679","type":0,"content":"seems like im fully compliant with the docs","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1117035503443775538","filename":"image.png","size":64889,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1117035503443775538/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1117035503443775538/image.png","width":1002,"height":580,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:20:17.593000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117034704839917609","type":0,"content":"Hello! Has anyone seen this one?","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:17:07.135000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117034680605220954","type":0,"content":"","channel_id":"1038097349660135474","author":{"id":"168844554286399488","username":"fotoflo","global_name":"fotoflo","avatar":"17ac4dd69d915d4c19ce3e1787b971d8","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1117034680387125298","filename":"image.png","size":42501,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1117034680387125298/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1117034680387125298/image.png","width":827,"height":187,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:17:01.357000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117033679110295583","type":19,"content":"That seems about right. I remember having to install psycopg to get it to work…","channel_id":"1038097349660135474","author":{"id":"1090080153658466434","username":"RishniRatnam","global_name":null,"avatar":"68a7ebf1825618abcfd89b80e8ffb89b","discriminator":"9200","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"719286426063339571","username":"trouble_","avatar":"94dc5e5945326bed94b71db1fc9cb3b2","discriminator":"4085","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:13:02.582000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1117030496333996052"},"referenced_message":{"id":"1117030496333996052","type":0,"content":"https://github.com/hwchase17/langchain/issues/3467 I think its this","channel_id":"1038097349660135474","author":{"id":"719286426063339571","username":"trouble_","global_name":null,"avatar":"94dc5e5945326bed94b71db1fc9cb3b2","discriminator":"4085","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchain/issues/3467","title":"Missing Dependency for PostgresChatMessageHistory (dependent on psy...","description":"The PostgresChatMessageHistory class. Uses psygopg 3; however, the pyproject.toml file only includes psycopg2-binary instead of psycopg[binary](psycopg 3). Proposed solution: Add psycopg[binary]==3...","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/727c0b12a4480eed969ebfc51aa261ca7bfff6a5e1407e9899856b1b489460dc/hwchase17/langchain/issues/3467","proxy_url":"https://images-ext-2.discordapp.net/external/qrX483U_Hk1WNvkmgI_UPuVLhCwjqxgAToKZ6bhQF-g/https/opengraph.githubassets.com/727c0b12a4480eed969ebfc51aa261ca7bfff6a5e1407e9899856b1b489460dc/hwchase17/langchain/issues/3467","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:00:23.749000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1117030496333996052","type":0,"content":"https://github.com/hwchase17/langchain/issues/3467 I think its this","channel_id":"1038097349660135474","author":{"id":"719286426063339571","username":"trouble_","global_name":null,"avatar":"94dc5e5945326bed94b71db1fc9cb3b2","discriminator":"4085","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchain/issues/3467","title":"Missing Dependency for PostgresChatMessageHistory (dependent on psy...","description":"The PostgresChatMessageHistory class. Uses psygopg 3; however, the pyproject.toml file only includes psycopg2-binary instead of psycopg[binary](psycopg 3). Proposed solution: Add psycopg[binary]==3...","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/727c0b12a4480eed969ebfc51aa261ca7bfff6a5e1407e9899856b1b489460dc/hwchase17/langchain/issues/3467","proxy_url":"https://images-ext-2.discordapp.net/external/qrX483U_Hk1WNvkmgI_UPuVLhCwjqxgAToKZ6bhQF-g/https/opengraph.githubassets.com/727c0b12a4480eed969ebfc51aa261ca7bfff6a5e1407e9899856b1b489460dc/hwchase17/langchain/issues/3467","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T10:00:23.749000+00:00","edited_timestamp":null,"flags":0,"components":[],"reactions":[{"emoji":{"id":null,"name":"👍"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}]},{"id":"1117029736674250823","type":0,"content":"<@1090080153658466434> <@399703416194203658>\n```\nno pq wrapper available.\nAttempts made:\n- couldn't import psycopg 'c' implementation: No module named 'psycopg_c'\n- couldn't import psycopg 'binary' implementation: No module named 'psycopg_binary'\n- couldn't import psycopg 'python' implementation: libpq library not found\n```","channel_id":"1038097349660135474","author":{"id":"719286426063339571","username":"trouble_","global_name":null,"avatar":"94dc5e5945326bed94b71db1fc9cb3b2","discriminator":"4085","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"399703416194203658","username":"bigbeard","avatar":"d8f3fd33202075cd83c38160b4a75475","discriminator":"1726","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null},{"id":"1090080153658466434","username":"RishniRatnam","avatar":"68a7ebf1825618abcfd89b80e8ffb89b","discriminator":"9200","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T09:57:22.632000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1117029586291654686","type":0,"content":"bug report for PostgresChatMessageHistory\nhttps://discord.com/channels/1038097195422978059/1102515876391026688/1117029432931135558","channel_id":"1038097349660135474","author":{"id":"719286426063339571","username":"trouble_","global_name":null,"avatar":"94dc5e5945326bed94b71db1fc9cb3b2","discriminator":"4085","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T09:56:46.778000+00:00","edited_timestamp":"2023-06-10T09:56:56.103000+00:00","flags":0,"components":[]},{"id":"1117004276473008200","type":0,"content":"Has anybody implemented SelfQueryRetriever by indexing the codebase?","channel_id":"1038097349660135474","author":{"id":"826654623921340426","username":"jatingarg619","global_name":null,"avatar":"1f9a670197bf3ba84172293ae93e1c04","discriminator":"1658","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T08:16:12.447000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116902645454610533","type":0,"content":"ClientConnectorCertificateError: Cannot connect to host python.langchain.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1002)')]","channel_id":"1038097349660135474","author":{"id":"604291533608452099","username":"supernitin","global_name":null,"avatar":null,"discriminator":"4568","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T01:32:21.724000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116902462566174741","type":0,"content":"Hello. I’m running LangChain  in VSC w/ the Jupyter extension…on macOS. I am trying to load websites into an index for analysis.  But am facing SSL error issues. Should this work? \n\n# fixes a bug with asyncio and jupyter\nimport nest_asyncio\n\nnest_asyncio.apply()\n\nfrom langchain.document_loaders.sitemap import SitemapLoader\n\nsitemap_loader = SitemapLoader(web_path=\"https://langchain.readthedocs.io/sitemap.xml\")\nsitemap_loader.requests_kwargs = {\"verify\": False}\n\ndocs = sitemap_loader.load()","channel_id":"1038097349660135474","author":{"id":"604291533608452099","username":"supernitin","global_name":null,"avatar":null,"discriminator":"4568","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T01:31:38.120000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116901661533798430","type":0,"content":"Hey everyone, been having 2 werid issues with chatopenai llm\n\n1 - whenever i get a response it prefaces it with \"chatbot: \"\n2- after like 3 responses it starts to autocomplete the rest of the discussion\n\nany advice?","channel_id":"1038097349660135474","author":{"id":"275866688933724160","username":"Damis","global_name":null,"avatar":"6865f487c315963b8929731510d52a2d","discriminator":"9861","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1116901661366038608","filename":"Screenshot_2023-06-09_at_9.28.15_PM.png","size":63881,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1116901661366038608/Screenshot_2023-06-09_at_9.28.15_PM.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1116901661366038608/Screenshot_2023-06-09_at_9.28.15_PM.png","width":645,"height":467,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-10T01:28:27.139000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116867528510156830","type":0,"content":"In my particular case, I'm asking the agent to produce some JavaScript code for a particular software by targeting at the software documentation. The RetrievalQA chain produces the code. Whereas the ZeroShotAgent keeps asking the tool the specifics of the code logic and the tool fails to answer those detailed questions.","channel_id":"1038097349660135474","author":{"id":"823323631848259645","username":"gmanepal","global_name":"GM","avatar":null,"discriminator":"0631","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T23:12:49.192000+00:00","edited_timestamp":"2023-06-09T23:13:08.757000+00:00","flags":0,"components":[]},{"id":"1116866470572462080","type":0,"content":"Hi. When I use ChatOpenAI using a RetrievalQA chain against a vector storage, I get the answer that I want. Whereas when I use ChatOpenAI using ZeroShotReactAgent (and use the RetrievalQA chain as the only tool), it's spinning. The ZeroShotAgent tries to micro analyze the task and the RetrievalQA chain doesn't have answers at that level of granularity. Any guidance on how to proceed?","channel_id":"1038097349660135474","author":{"id":"823323631848259645","username":"gmanepal","global_name":"GM","avatar":null,"discriminator":"0631","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T23:08:36.960000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116853901874962442","type":0,"content":"I am trying to use search ditance with conversational retrieval chain, but i am getting same error as the guy here in the issues. Nobody seemts to answer those issues haha.. interesting for that large frameowrk\n\nhttps://github.com/hwchase17/langchain/issues/3178","channel_id":"1038097349660135474","author":{"id":"376809451044470785","username":"Ziigaa","global_name":null,"avatar":"92db54d6a0cfb151255c4fcc16ce9c9e","discriminator":"7727","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchain/issues/3178","title":"Error in running search_distance  with ConversationalRetrievalChain...","description":"Hi I have one question I want to use search_distance with ConversationalRetrievalChain Here is my code: vectordbkwargs = {\"search_distance\": 0.9} bot_message = qa.run({\"question\"...","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/6f78a0c2ff67e130acb02b4f255743a75b92f7aca1f687a7b9bb589108aaf21d/hwchase17/langchain/issues/3178","proxy_url":"https://images-ext-2.discordapp.net/external/TpB0anLvdStFZEXoauLF1rCIhgdSjMllfJskTb5_yAM/https/opengraph.githubassets.com/6f78a0c2ff67e130acb02b4f255743a75b92f7aca1f687a7b9bb589108aaf21d/hwchase17/langchain/issues/3178","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T22:18:40.349000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116844945354014741","type":19,"content":"I think technically you should be able to if you are using lets say Redis as your memory . But then you will have to add a logic to identify which chains should use which items in the memory. If you are using memorybuffer, then it probably becomes complex and not feasible (one due to token limit, other if the chains are running in two different session how you make one session use the buffer if the other)","channel_id":"1038097349660135474","author":{"id":"1054527970938720296","username":"Rajib","global_name":null,"avatar":null,"discriminator":"2189","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"943884739713060906","username":"TPsilly","avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T21:43:04.948000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116833249281441894"},"referenced_message":{"id":"1116833249281441894","type":0,"content":"does anyone know if its possible to use same memory object for 2 different chains?","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T20:56:36.387000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116833249281441894","type":0,"content":"does anyone know if its possible to use same memory object for 2 different chains?","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T20:56:36.387000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116817819644993706","type":19,"content":"This is very interesting. I was actually talking about a similar thing yesterday where I have LLM powered services deployed as pods in K8s and then create an orchestration layer like Airflow to stitch together LLM + non-LLM services to perform a business process. I was thinking an alternate option of using Agent and tool based orchestration to do this workflow. I would love to hear any other alternate solutions on this. The example of the use case is lets say on a e-commerce portal I search a product, another service to compare the price of product and find the cheapest one and then call a shopping cart, pricing service to close the transaction","channel_id":"1038097349660135474","author":{"id":"1054527970938720296","username":"Rajib","global_name":null,"avatar":null,"discriminator":"2189","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"703607660599181377","username":"hwchase17","avatar":null,"discriminator":"0219","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T19:55:17.675000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1044983360679841833"},"referenced_message":{"id":"1044983360679841833","type":19,"content":"first class support/ a focus on LLMs and LLM powered workflows. I would bet you could probably use Airflow and ZenML in a similar way, but it would just take a bit more effort. Also, most of the dev effort on LangChain so far has been aimed at more experimental/prototyping workflows. When we start thinking about productionalizing, its possible we build on top of something like airflow for some use cases. To that end, I'd love to chat with you at some point to better understand your use case!","channel_id":"1038097349660135474","author":{"id":"703607660599181377","username":"hwchase17","global_name":null,"avatar":null,"discriminator":"0219","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"840186354633015336","username":"richardblythman | Algovera.ai","avatar":"f42ec75694c506a25849235bbeac9c13","discriminator":"3425","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2022-11-23T14:30:48.038000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1044981538590302258"}}},{"id":"1116805620079788162","type":0,"content":"<@1072591948499664996> Can you give me an example of an LLMRouterChain implementation that does not use a multi prompt template?","channel_id":"1038097349660135474","author":{"id":"1058241473813938208","username":"Fima","global_name":null,"avatar":null,"discriminator":"1892","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1072591948499664996","username":"kapa.ai","avatar":"09e7b0315ef53d57936eb7d461f40224","discriminator":"2237","public_flags":0,"flags":0,"bot":true,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T19:06:49.072000+00:00","edited_timestamp":null,"flags":32,"components":[],"thread":{"id":"1116805620079788162","guild_id":"1038097195422978059","parent_id":"1038097349660135474","owner_id":"1072591948499664996","type":11,"name":"Can you give me an example of an LLMRouterChain implementation that does not use a multi p","last_message_id":"1116805710479630420","thread_metadata":{"archived":false,"archive_timestamp":"2023-06-09T19:06:49.394000+00:00","auto_archive_duration":1440,"locked":false,"create_timestamp":"2023-06-09T19:06:49.394000+00:00"},"message_count":3,"member_count":3,"rate_limit_per_user":0,"flags":0,"total_message_sent":3,"member_ids_preview":["1058241473813938208","1072591948499664996","437808476106784770"]}},{"id":"1116790629180112956","type":0,"content":"Hey, just a quick question I couldn't verify in the documentation--I remember at one point hearing that the maximum number of tools per agent is 3 tools, is that true? I understand of course it's better to keep it down to as few tools as possible so the agent doesn't get confused, I just want to see if I can go over 3.","channel_id":"1038097349660135474","author":{"id":"355742577179492355","username":"Alchemicat","global_name":null,"avatar":"f03910e4c7b58b12039ff06c329e91ff","discriminator":"2635","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T18:07:14.963000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116787858171240478","type":19,"content":"Thank you brother","channel_id":"1038097349660135474","author":{"id":"654988502320021515","username":"M4k Dev","global_name":null,"avatar":"c6095e6ef03797e7e2383f43eafe46ee","discriminator":"4640","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"706926250723115019","username":"Woover","avatar":"c96a0eec06c6b0aeb84f2193ba81d65a","discriminator":"8079","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"Yehonatan Yosefi","avatar_decoration":null,"display_name":"Yehonatan Yosefi","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T17:56:14.303000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116725778734911538"},"reactions":[{"emoji":{"id":null,"name":"👍"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}],"referenced_message":{"id":"1116725778734911538","type":19,"content":"you're talking to the llm in a non-traditional way\ntry writing the answer:\nA: Open Ended Question\nA: Closed Question\n\nand parse it accordingly\nalso, include questions without question mark, and that are ambiguos(try asking gpt4 for a good list)\nI'd use gpt 3.5 if possible, the 3.5 turbo is fast and isn't expensive","channel_id":"1038097349660135474","author":{"id":"706926250723115019","username":"Woover","global_name":"Yehonatan Yosefi","avatar":"c96a0eec06c6b0aeb84f2193ba81d65a","discriminator":"8079","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"654988502320021515","username":"M4k Dev","avatar":"c6095e6ef03797e7e2383f43eafe46ee","discriminator":"4640","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T13:49:33.412000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116660680070811671"}}},{"id":"1116741843275763733","type":0,"content":"I cannot get pyodbc to connect to SQL Server. I'm running SQL Server on a GCP VM with public ip address, Microsoft SQL Server 2019 (RTM-CU20) (KB5024276) - 15.0.4312.2 (X64) , VM Details: Linux 5.15.0-1035-gcp #43~20.04.1-Ubuntu SMP Mon May 22 16:49:11 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux. using Colab i'm trying to establish a connection with the server ```connection_string = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n\ntry:\n    connection = pyodbc.connect(connection_string)\n    print('Connection successful')\nexcept pyodbc.Error as e:\n    print('Connection failed:', str(e))``` i keep getting the following error: ```Connection failed: ('01000', \"[01000] [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 17 for SQL Server' : file not found (0) (SQLDriverConnect)\")``` I have tried uninstalling and reinstalling odbc17 as well as 18, reinstalled sql server, changed $PATH multiple times with different settings but just can't get it to work. Can anyone help? I can connect to the server using Azure Data Studio installed on my Mac Pro M1. when i try to connect locally on the VM, i.e. server = 'localhost' that works. msodbcsql17 and unixodbc is installed correctly.  here's etc/odbcinst.ini : [ODBC Driver 17 for SQL Server]\nDescription=Microsoft ODBC Driver 17 for SQL Server\nDriver=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.10.so.2.1\nUsageCount=1 . SQL server is listening on default port. I've set up firewall rules correctly since Azure Data Studio can infact connect to the server. Any help is much appreciated. Thanks!","channel_id":"1038097349660135474","author":{"id":"540950164786118657","username":"dvznby0","global_name":null,"avatar":"5109446d38177666a1424abe4a055459","discriminator":"9026","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T14:53:23.497000+00:00","edited_timestamp":"2023-06-09T14:59:47.830000+00:00","flags":0,"components":[]},{"id":"1116736452181630996","type":0,"content":"i am using langchain, my dataset is like this:\n\"Customer .....'s  id is \".....\", purchased course is \"----\", title is \"....\", country is \"...\".\"\n\"Customer ...'s  id is \"...\", purchased course is \"----\", title is \"....\", country is \"...\", industry is \"...\".\"\n\"Customer ....'s  id is \"...\", purchased course is \"-----\", title is \"....\", country is \"...\".\"\n\n\nmy prompt is this:\nSuggest 5 customers  who can purchase course \"-----\".  Suggest only if customers did not purchase before.\n\nbut the response is this:\n{'query': 'Suggest 5 customers  who can purchase course \"------\". \n Suggest only if customers did not purchase before. ', 'result': \" I don't know.\n\nwhat is and where is the problem? why is not giving the good results? My dataset is wrong or my prompt question is wrong? Please help me!","channel_id":"1038097349660135474","author":{"id":"463275812012163084","username":"Refik","global_name":null,"avatar":null,"discriminator":"4851","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T14:31:58.160000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116725778734911538","type":19,"content":"you're talking to the llm in a non-traditional way\ntry writing the answer:\nA: Open Ended Question\nA: Closed Question\n\nand parse it accordingly\nalso, include questions without question mark, and that are ambiguos(try asking gpt4 for a good list)\nI'd use gpt 3.5 if possible, the 3.5 turbo is fast and isn't expensive","channel_id":"1038097349660135474","author":{"id":"706926250723115019","username":"Woover","global_name":"Yehonatan Yosefi","avatar":"c96a0eec06c6b0aeb84f2193ba81d65a","discriminator":"8079","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"654988502320021515","username":"M4k Dev","avatar":"c6095e6ef03797e7e2383f43eafe46ee","discriminator":"4640","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T13:49:33.412000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116660680070811671"},"reactions":[{"emoji":{"id":null,"name":"👍"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}],"referenced_message":{"id":"1116660680070811671","type":0,"content":"I'm trying to get an LLM to tell me if a question is open ended or not but I'm getting inconsistent results.\nAnyone have some tips to give me on how to achieve this?\n\ndavinci-003 gets this right most of the time but not always.\nChatGPT gets it right.\n\n You decide if a message is open ended or not.\n   Respond YES if the message is open ended.\n   Respond NO if it is not open ended.\n   \n\n   Here's an a few examples of an open-ended question:\n   Q: Whats your favorite thing to do?\n   A: YES\n\n   Q: How was your day?\n   A: YES\n\n   Q: How do you feel about today?\n   A: YES\n Here are a few exampes questions that is not open-ended:\n  Q: If you have to choose black or white, what 's your favorite?\n  A: NO\n\n  Q: Do you like bacon or cheese best?\n  A: NO\n \n  Q: Are your parents old?\n  A: NO\n\n  Q: Do you like bread or milk best?\n  A: NO\n  \n \n Now, do this for real!\n Q: Japan and Korea is on the top of my list.\n A:","channel_id":"1038097349660135474","author":{"id":"654988502320021515","username":"M4k Dev","global_name":null,"avatar":"c6095e6ef03797e7e2383f43eafe46ee","discriminator":"4640","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T09:30:52.681000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116673458642890875","type":0,"content":"Is there recommended structure of json that goes well with jsonspec? In my case it’s loosely structured without description. Is it better to use vector agent to do the data search?","channel_id":"1038097349660135474","author":{"id":"1005040653895487538","username":"Hao","global_name":null,"avatar":null,"discriminator":"9971","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T10:21:39.330000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116672658302566411","type":0,"content":"Hi newbie here. I’m trying to use jsonspec agent to extract a pair  {domain:xxx, value:xxx} from a json file, but the agent sometimes finds the value and make up a random domain or the other way around.","channel_id":"1038097349660135474","author":{"id":"1005040653895487538","username":"Hao","global_name":null,"avatar":null,"discriminator":"9971","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T10:18:28.514000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116666199833579541","type":0,"content":"i'm curious to why","channel_id":"1038097349660135474","author":{"id":"358935632682156033","username":"DoubleAs","global_name":null,"avatar":"e2b7efbcef7e12f64f698865816bacad","discriminator":"0437","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T09:52:48.695000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116666164752424992","type":0,"content":"its able to pull current information about other things but not the time and date","channel_id":"1038097349660135474","author":{"id":"358935632682156033","username":"DoubleAs","global_name":null,"avatar":"e2b7efbcef7e12f64f698865816bacad","discriminator":"0437","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T09:52:40.331000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116665215145234462","type":0,"content":"Does anyone know why?","channel_id":"1038097349660135474","author":{"id":"358935632682156033","username":"DoubleAs","global_name":null,"avatar":"e2b7efbcef7e12f64f698865816bacad","discriminator":"0437","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T09:48:53.927000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116665182723244043","type":0,"content":"Hi guys i'm using Serpapi in my openai/langchain chatbot but for somereason when i try to use the chatbot to search for current data like the time its unable to do this and says that the data is 2021","channel_id":"1038097349660135474","author":{"id":"358935632682156033","username":"DoubleAs","global_name":null,"avatar":"e2b7efbcef7e12f64f698865816bacad","discriminator":"0437","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T09:48:46.197000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116660837554335754","type":0,"content":"Answer should be NO on the last one because it is not an open-ended question","channel_id":"1038097349660135474","author":{"id":"654988502320021515","username":"M4k Dev","global_name":null,"avatar":"c6095e6ef03797e7e2383f43eafe46ee","discriminator":"4640","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T09:31:30.228000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116660680070811671","type":0,"content":"I'm trying to get an LLM to tell me if a question is open ended or not but I'm getting inconsistent results.\nAnyone have some tips to give me on how to achieve this?\n\ndavinci-003 gets this right most of the time but not always.\nChatGPT gets it right.\n\n You decide if a message is open ended or not.\n   Respond YES if the message is open ended.\n   Respond NO if it is not open ended.\n   \n\n   Here's an a few examples of an open-ended question:\n   Q: Whats your favorite thing to do?\n   A: YES\n\n   Q: How was your day?\n   A: YES\n\n   Q: How do you feel about today?\n   A: YES\n Here are a few exampes questions that is not open-ended:\n  Q: If you have to choose black or white, what 's your favorite?\n  A: NO\n\n  Q: Do you like bacon or cheese best?\n  A: NO\n \n  Q: Are your parents old?\n  A: NO\n\n  Q: Do you like bread or milk best?\n  A: NO\n  \n \n Now, do this for real!\n Q: Japan and Korea is on the top of my list.\n A:","channel_id":"1038097349660135474","author":{"id":"654988502320021515","username":"M4k Dev","global_name":null,"avatar":"c6095e6ef03797e7e2383f43eafe46ee","discriminator":"4640","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T09:30:52.681000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116659663044350012","type":0,"content":"Hi guys!","channel_id":"1038097349660135474","author":{"id":"654988502320021515","username":"M4k Dev","global_name":null,"avatar":"c6095e6ef03797e7e2383f43eafe46ee","discriminator":"4640","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T09:26:50.203000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116641843069853737","type":0,"content":"Does anyone know how long caching lasts when using `InMemoryCache`  (the standard cache used when setting `cache: true` on the OpenAI llm) ?  Is there a specific length of time before it's cleared from memory?","channel_id":"1038097349660135474","author":{"id":"365544937367797762","username":"Marty","global_name":null,"avatar":"eb15f8199a6538b1b0e348015b8c9526","discriminator":"5304","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T08:16:01.590000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116633542491914333","type":0,"content":"is it possible to connect this ```agent = create_pandas_dataframe_agent(OpenAI(temperature=0), df, verbose=True)\n``` to a simpleChain?","channel_id":"1038097349660135474","author":{"id":"897492138416300052","username":"ElDiablo","global_name":"Admin","avatar":"c27d324215a2d0b1fb56f858a9e6621d","discriminator":"5947","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T07:43:02.578000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116630282875981825","type":0,"content":"Hey I am looking for a langchain Chatbot UI Package that has the fine grained control over the chat history like in the openAI Playground, e.g. the ability to create, edit and delete messages. All the chatbot packages I found so far are super basic. Any recommendations?","channel_id":"1038097349660135474","author":{"id":"374902921537781763","username":"Michael","global_name":null,"avatar":"fab402c188d384a1893dc49f84963f4c","discriminator":"0331","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T07:30:05.425000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116621178480623649","type":0,"content":"Is there a way to create langchain.embeddings on the llama model directly from Meta, without llama.cpp?","channel_id":"1038097349660135474","author":{"id":"392717162797596672","username":"Homosexual Toaster","global_name":null,"avatar":"9ed8b3e96e10aee283a664c112fd368c","discriminator":"6083","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T06:53:54.768000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116605461437890590","type":0,"content":"Hello, was wondering what graph databases are currently supported in langchain and if there is any plan to support ArangoDB?","channel_id":"1038097349660135474","author":{"id":"1114206618570203276","username":"Pravin","global_name":null,"avatar":null,"discriminator":"5509","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T05:51:27.533000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116603811012825150","type":0,"content":"Hello everyone, I am having an issue/I don't get how to add a json response to a template, could you help me to understand how do it properly please? \n\nThis is an example:\n```\nmy_data = requests.get(domain).json()\ntemplate = f\"Extract feature variable from this json file {my_data}\"\nllm = OpenAI(temperature=0.9)\nchain = LLMChain(llm=llm, prompt=template, verbose=True)\nseq_chain = SimpleSequentialChain(chains=[chain, ... ], verbose=True)\n\n```\n\n**this** gives me an error, because I cannot append data to template.\n\n```\nline 341, in pydantic.main.BaseModel.__init__\npydantic.error_wrappers.ValidationError: 1 validation error for PromptTemplate\n```\n\n```\n line 341, in pydantic.main.BaseModel.__init__\npydantic.error_wrappers.ValidationError: 1 validation error for PromptTemplate\n__root__\n  unmatched '{' in format spec (type=value_error)\n```\n\nFrom:  https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html#what-is-a-prompt-template\nQuestions:\n- why I cannot add any variable to the template? \n```\nfrom langchain import PromptTemplate\n\n\ntemplate = \"\"\"\nI want you to act as a naming consultant for new companies.\nWhat is a good name for a company that makes {product}?\n\"\"\"\n\nprompt = PromptTemplate(\n    input_variables=[\"product\"],\n    template=template,\n)\nprompt.format(product=\"colorful socks\")\n```","channel_id":"1038097349660135474","author":{"id":"897492138416300052","username":"ElDiablo","global_name":"Admin","avatar":"c27d324215a2d0b1fb56f858a9e6621d","discriminator":"5947","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T05:44:54.041000+00:00","edited_timestamp":"2023-06-09T06:17:59.408000+00:00","flags":0,"components":[]},{"id":"1116587791472664666","type":0,"content":"my script\n```\nmodel_name = \"GanymedeNil/text2vec-large-chinese\"\n    gpu = rh.cluster(name=\"local_embedding\", ips=['172.31.29.85'],ssh_creds={'ssh_user': 'ubuntu', 'ssh_private_key':'/home/work/.ssh/id_rsa'})\n    hf = SelfHostedHuggingFaceEmbeddings(model_id=model_name, hardware=gpu)\n```","channel_id":"1038097349660135474","author":{"id":"1088761362001428480","username":"xxm404","global_name":null,"avatar":null,"discriminator":"6010","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T04:41:14.685000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116587634165284925","type":0,"content":"when i use SelfHostedHuggingFaceEmbeddings i get this error\n```\n2023-06-09 04:35:48,492| ERROR   | Secsh channel 0 open FAILED: Connection refused: Connect failed\nERROR | 2023-06-09 04:35:48,492 | Secsh channel 0 open FAILED: Connection refused: Connect failed\n2023-06-09 04:35:48,492| ERROR   | Could not establish connection from local ('127.0.0.1', 50052) to remote ('127.0.0.1', 50052) side of the tunnel: open new channel ssh error: ChannelException(2, 'Connect failed')\nERROR | 2023-06-09 04:35:48,492 | Could not establish connection from local ('127.0.0.1', 50052) to remote ('127.0.0.1', 50052) side of the tunnel: open new channel ssh error: ChannelException(2, 'Connect failed')\n```","channel_id":"1038097349660135474","author":{"id":"1088761362001428480","username":"xxm404","global_name":null,"avatar":null,"discriminator":"6010","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T04:40:37.180000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116558544884486214","type":0,"content":"installed pytorch + cuda 11.8. didn't work. works with cuda 11.7. (pip install torch torchvision torchaudio)","channel_id":"1038097349660135474","author":{"id":"1113525897060958228","username":"crn121","global_name":null,"avatar":null,"discriminator":"8707","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T02:45:01.755000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116549778755551316","type":0,"content":"is there a list of python packages that i need to install to get libcudart.so.11 , libcublas etc.","channel_id":"1038097349660135474","author":{"id":"1113525897060958228","username":"crn121","global_name":null,"avatar":null,"discriminator":"8707","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T02:10:11.747000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116549229519839304","type":0,"content":"Python 3.9.2 (default, Feb 28 2021, 17:03:44)\n[GCC 10.2.1 20210110] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n> import llama_cpp\n> Traceback (most recent call last):\n>   File \"/home/crn121/py3ai/lib/python3.9/site-packages/llama_cpp/llama_cpp.py\", line 64, in _load_shared_library\n>     return ctypes.CDLL(str(_lib_path), **cdll_args)\n>   File \"/usr/lib/python3.9/ctypes/__init__.py\", line 374, in __init__\n>     self._handle = _dlopen(self._name, mode)\n> OSError: libcudart.so.11.0: cannot open shared object file: No such file or directory\n> \n> During handling of the above exception, another exception occurred:\n> \n> Traceback (most recent call last):\n>   File \"<stdin>\", line 1, in <module>\n>   File \"/home/crn121/py3ai/lib/python3.9/site-packages/llama_cpp/__init__.py\", line 1, in <module>\n>     from .llama_cpp import *\n>   File \"/home/crn121/py3ai/lib/python3.9/site-packages/llama_cpp/llama_cpp.py\", line 77, in <module>\n>     _lib = _load_shared_library(_lib_base_name)\n>   File \"/home/crn121/py3ai/lib/python3.9/site-packages/llama_cpp/llama_cpp.py\", line 66, in _load_shared_library\n>     raise RuntimeError(f\"Failed to load shared library '{_lib_path}': {e}\")\n> RuntimeError: Failed to load shared library '/home/crn121/py3ai/lib/python3.9/site-packages/llama_cpp/libllama.so': libcudart.so.11.0: cannot open shared object file: No such file or directory\n> >>>","channel_id":"1038097349660135474","author":{"id":"1113525897060958228","username":"crn121","global_name":null,"avatar":null,"discriminator":"8707","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T02:08:00.799000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116549221206720562","type":0,"content":"ok. llama_cpp is working fine with ggml and gpu offload. now i'm trying to use langchan with llama-cpp-python and its failing.","channel_id":"1038097349660135474","author":{"id":"1113525897060958228","username":"crn121","global_name":null,"avatar":null,"discriminator":"8707","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T02:07:58.817000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116548416638550086","type":0,"content":"no idea, I've never installed them with python","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T02:04:46.993000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116548244806324336","type":0,"content":"thanks. do you happen to know the python package names for these.","channel_id":"1038097349660135474","author":{"id":"1113525897060958228","username":"crn121","global_name":null,"avatar":null,"discriminator":"8707","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T02:04:06.025000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116547974605062196","type":0,"content":"you need to install cuda and cudNN","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T02:03:01.604000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116547808149917821","type":0,"content":"folks, i'm trying to use llama_cpp with gpu support. installed llama-cpp-python with !CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python. i'm getting libcudart.so.11.0: cannot open shared object file: No such file or directory. Are there any python packages that i need to install to get the gpu related environment.","channel_id":"1038097349660135474","author":{"id":"1113525897060958228","username":"crn121","global_name":null,"avatar":null,"discriminator":"8707","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T02:02:21.918000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116541640513949706","type":0,"content":"does anyone know if its possible to make 2 chains use the same memory object?","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T01:37:51.439000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116519171598073886","type":0,"content":"hey guys. I'm playing with the PlanAndExecute agent described here: https://python.langchain.com/en/latest/modules/agents/plan_and_execute.html.  However, every time I run it I get a \"InvalidRequestError: This model's maximum context length\". Does anybody know how to solve this?","channel_id":"1038097349660135474","author":{"id":"267784444688072705","username":"Edmar","global_name":null,"avatar":"d1b13d94544efee73f95377c18ee4686","discriminator":"4584","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-09T00:08:34.432000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116505857149116486","type":0,"content":"<@1072591948499664996> how do I query my redis vector database while also filtering by certain metadata?","channel_id":"1038097349660135474","author":{"id":"225070547933855744","username":".arctik","global_name":"ArctiK","avatar":"29bcba85f0e1773b9fe6f2b4e193354d","discriminator":"0","public_flags":512,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1072591948499664996","username":"kapa.ai","avatar":"09e7b0315ef53d57936eb7d461f40224","discriminator":"2237","public_flags":0,"flags":0,"bot":true,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T23:15:40.020000+00:00","edited_timestamp":null,"flags":32,"components":[],"thread":{"id":"1116505857149116486","guild_id":"1038097195422978059","parent_id":"1038097349660135474","owner_id":"1072591948499664996","type":11,"name":"how do I query my redis vector database while also filtering by certain metadata?","last_message_id":"1116508104813723768","thread_metadata":{"archived":false,"archive_timestamp":"2023-06-08T23:15:40.194000+00:00","auto_archive_duration":1440,"locked":false,"create_timestamp":"2023-06-08T23:15:40.194000+00:00"},"message_count":11,"member_count":3,"rate_limit_per_user":0,"flags":0,"total_message_sent":11,"member_ids_preview":["437808476106784770","1072591948499664996","225070547933855744"]}},{"id":"1116487201065271447","type":0,"content":"Hello, I'm working looking for AI agents - is langchain developing some? I've seen you use GPT with Wolfram. Anyone has tried?","channel_id":"1038097349660135474","author":{"id":"742725855897190421","username":"unicorn","global_name":null,"avatar":"6437618a6b5724ebddc3dc48be234112","discriminator":"4636","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T22:01:32.063000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116447950797803671","type":0,"content":"Has anyone handled putting an output parser specifically on a tool?\nI have a tool that will output something like {'year_1' : X, 'year_2' : Y, 'year_3': Z} - but when asked, my agent will usually only return the year 3 value. I'd like it to display the entire timeseries.","channel_id":"1038097349660135474","author":{"id":"359842104798871563","username":"yungseneca","global_name":null,"avatar":"3d049fc03743b85f529dfe952acde880","discriminator":"8481","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T19:25:34.070000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116444526538653698","type":0,"content":"Hi, I'm trying to run langchain-server (in ubuntu/wsl2). It downloads and runs the docker file ok, and I get:\n\nlangchain-frontend_1  |   ➜  Local:   http://localhost:4173/\nlangchain-frontend_1  |   ➜  Network: http://172.18.0.4:4173/\n\nBut no response on these urls. It does responds on http://localhost:8000 with a \"not found\" json. It also seems to be receiving messages from my python program. I just can't load up the front end to view the trace. Any ideas?","channel_id":"1038097349660135474","author":{"id":"118330246796804097","username":".calytrix","global_name":"Calytrix","avatar":"d9979efb92d9dc34b2795058a9e48edf","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T19:11:57.663000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116432043962806333","type":0,"content":"Hey any suggestions for initiating a CHAT_CONVERSATIONAL_REACT_DESCRIPTION agent with existing messages, I'm currently somewhat hackily doing this ```memory.chat_memory.messages = chat_messages```. But, I'm also not sure if that's intiializing the scratchpad of the agent or the prior chat history...\n\nThen passing the memory in like so \n```\nagent_chain = initialize_agent(\n        tools,\n        llm,\n        agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n        verbose=True,\n        memory=memory,\n        handle_parsing_errors=True,\n    )\n\n```","channel_id":"1038097349660135474","author":{"id":"885924166736441404","username":"TedT","global_name":null,"avatar":null,"discriminator":"2152","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T18:22:21.585000+00:00","edited_timestamp":"2023-06-08T18:22:49.233000+00:00","flags":0,"components":[]},{"id":"1116405487466975272","type":0,"content":"Please check it out:\nhttps://github.com/hwchase17/langchain/issues/5890","channel_id":"1038097349660135474","author":{"id":"376809451044470785","username":"Ziigaa","global_name":null,"avatar":"92db54d6a0cfb151255c4fcc16ce9c9e","discriminator":"7727","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchain/issues/5890","title":"Issue: ConversationalRetrievalChain with custom prompt template · I...","description":"Issue you'd like to raise. Hello everyone! I can't set up to sucessfully use custom QA prompt template with my ConversationalRetrievalChain I am using LangChain v0.0.191 with chromaDb vecto...","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/5a59f9eda483a464428f900900fb776591d6f82ef7bec3ae0574380b8b49ba7e/hwchase17/langchain/issues/5890","proxy_url":"https://images-ext-2.discordapp.net/external/r0fkd0X97aywqaILhVFxLyvwIP32-GwDxdg50DqjMWU/https/opengraph.githubassets.com/5a59f9eda483a464428f900900fb776591d6f82ef7bec3ae0574380b8b49ba7e/hwchase17/langchain/issues/5890","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T16:36:50.023000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116379009614364712","type":0,"content":"Hi, I am passing QA prompt to conversationalretrieval chain like that:\n`              retriever = chroma_Vectorstore.as_retriever(qa_template=QA_PROMP_ALL_KNOWLEDGE, search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.2})\n\n                self.chain = ConversationalRetrievalChain.from_llm(self.llm, retriever,\n                                                                   combine_docs_chain_kwargs={'prompt': QA_PROMP_ALL_KNOWLEDGE},\n                                                                    return_source_documents=True,verbose=True, \n                                                                    memory=self.memory)`\n\nbut it doesn't use that. am i missing something?","channel_id":"1038097349660135474","author":{"id":"376809451044470785","username":"Ziigaa","global_name":null,"avatar":"92db54d6a0cfb151255c4fcc16ce9c9e","discriminator":"7727","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T14:51:37.211000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116353812186280056","type":0,"content":"Another question: I have a LLMChain that is supposed to return a JSON output. Instead it returns the text \"The output should be:\" and then the JSON object. When I ran the same prompt through the UI, I only got the JSON. Is Langchain processing the output and including this section?","channel_id":"1038097349660135474","author":{"id":"244182157013155851","username":"BuahahaXD","global_name":null,"avatar":"e9b0cf9b9bde2666416cdf785f99a190","discriminator":"2920","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T13:11:29.676000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116347233852465202","type":0,"content":"Is it possible to divide one LLMs response into pieces, process them independently in one chain and then combine the results? One prompt is too long and I would like to divide it. I have a feeling that it is not possible using the SequentialChain","channel_id":"1038097349660135474","author":{"id":"244182157013155851","username":"BuahahaXD","global_name":null,"avatar":"e9b0cf9b9bde2666416cdf785f99a190","discriminator":"2920","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T12:45:21.279000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116336117554356225","type":0,"content":"Hey so i am making a basic doc qa bot using langchain and streamlit. Now the previous conversations are not being stored as streamlit runs the whole code on each new entry. I have saved the questions and their answers in a list and am saving the list using session state of streamlit. Now how do i make the chain take input from my docs as well as from the list. Or is there any other way to store the previous conversations? ConversationBufferMemory is also not working due to the streamlit issue. \n\n'''\n        ans_chain = load_qa_chain(OpenAI(temperature = 0.1), chain_type=\"stuff\")\n        ans = ans_chain.run(input_documents = docs, question = ans_query)\n'''","channel_id":"1038097349660135474","author":{"id":"712028193472905308","username":"NEO","global_name":null,"avatar":null,"discriminator":"9368","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T12:01:10.947000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116312187036762122","type":0,"content":"Question, I have thousands of files and i want to use semantic search on all of them, how would you approach it? How can i store a faiss object in a db","channel_id":"1038097349660135474","author":{"id":"934812663106662430","username":"Dreezy","global_name":null,"avatar":"693e45a8158da8bb724580d867bfab89","discriminator":"1337","public_flags":256,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T10:26:05.467000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116304435962978374","type":0,"content":"hey guys, we are using OpenAI in Azure to answer questions based on internal content. The content is searched via Azure Cognitive search. This all works really well. The problem starts when the content we get from Cognitive Search is too long. We run out of tokens. So we need to chunk them. \nMy question is now, if we chunk the content after pulling the search result, we do not know in which part of the chunk we will find the answer. \nHas anybody done something similar and can point me in the right direction?","channel_id":"1038097349660135474","author":{"id":"388067386269630487","username":"BrainCandy","global_name":null,"avatar":null,"discriminator":"8846","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T09:55:17.467000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116286305123446875","type":19,"content":"Coool thanks a lot","channel_id":"1038097349660135474","author":{"id":"787705681574625310","username":"Skittle","global_name":null,"avatar":"e0c155503c4526f2d059bdfd9951ef5d","discriminator":"3972","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"229576111212855296","username":"coffeevampir3","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"Coffee Vampire","avatar_decoration":null,"display_name":"Coffee Vampire","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T08:43:14.738000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116249219838267453"},"referenced_message":{"id":"1116249219838267453","type":0,"content":"There's some connecting ideas with the parsing the output as well depending on how you set things up, I think there's a good overview here <https://www.youtube.com/watch?v=UVn2NroKQCw>","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:15:52.917000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116282593395093535","type":0,"content":"Hi\n\nI am trying to write a program that will use Langchain to interact with LLM to generate SQL queries for the data stored in our database from the question asked in natural language. I am able to do it with one prompt template but having a single prompt template is not enough to answer various business questions. Therefore, I am making use of `LLMRouterChain` and `MultiPromptChain` to select the most relevant template out of many and finally use that template to generate SQL queries from the LLM. I used the example provided in the Langchain documentation at the following link: https://python.langchain.com/en/latest/modules/chains/generic/router.html\n\nHere, in this piece of code:\n```destination_chains = {}\nfor p_info in prompt_infos:\n    name = p_info[\"name\"]\n    prompt_template = p_info[\"prompt_template\"]\n    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n    chain = LLMChain(llm=llm, prompt=prompt)\n    destination_chains[name] = chain\ndefault_chain = ConversationChain(llm=llm, output_key=\"text\")```\n\nI am using `SQLDatabaseChain` instead of just `LLMChain`  because I want to pass table info as well when asking `LLM` to create an SQL query. So, my code looks like:\n\n```for p_info in prompt_infos:\n    name = p_info[\"name\"]\n    prompt_template = p_info[\"prompt_template\"]\n    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\", \"table_info\", \"dialect\"])\n    sql_chain = SQLDatabaseChain.from_llm(llm, db, prompt=prompt, verbose=True, use_query_checker=True)\n    chain = sql_chain\n    destination_chains[name] = chain\n```\nbut I keep getting the following error:\n`pydantic.error_wrappers.ValidationError: 30 validation errors for MultiPromptChain`\n\nPlease suggest the possible solutions.\nThanks","channel_id":"1038097349660135474","author":{"id":"484179472979984407","username":"kkdevenda","global_name":null,"avatar":null,"discriminator":"8443","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T08:28:29.793000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116270856193191976","type":0,"content":"my output is a list of parsed objects, e.g. {\"recipes\": [{name: recipe1, ...}, {name: recipe2, ..} ...]} - perhaps I can manually parse each object and remove them from output that needs fixing. It wouldn't help if the entire structure is broken, but perhaps might reduce the amount of data sent back to the llm to be repaired.","channel_id":"1038097349660135474","author":{"id":"521394391550787614","username":"lekkerjohn","global_name":null,"avatar":"bc4920a920fba3bc29661e797725c951","discriminator":"0699","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T07:41:51.426000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116269732207796285","type":0,"content":"When using an outputfixing parser, I often exceed the maximum context length. I'm assuming that is because I am sending effectively almost the same information twice, once for the input text and once for the output that needs to be corrected. I am loath to split my original text  into smaller chunks. Is there another way to deal with this?","channel_id":"1038097349660135474","author":{"id":"521394391550787614","username":"lekkerjohn","global_name":null,"avatar":"bc4920a920fba3bc29661e797725c951","discriminator":"0699","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T07:37:23.447000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116268550332633151","type":0,"content":"What changes have been made into langchian Plus??","channel_id":"1038097349660135474","author":{"id":"1078326467437531168","username":"jirpm","global_name":null,"avatar":null,"discriminator":"1547","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T07:32:41.666000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116268188204802088","type":19,"content":"I had chat gpt make a diagram of the process:","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1116268188024451152","filename":"image.png","size":78788,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1116268188024451152/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1116268188024451152/image.png","width":845,"height":736,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T07:31:15.328000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116248788676378624"},"reactions":[{"emoji":{"id":null,"name":"❤️"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}],"referenced_message":{"id":"1116248788676378624","type":0,"content":"the technical part of ReAct is sort of difficult to describe, I don't think the paper does a good job but I'm not sure how to put things any differently","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:14:10.120000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116264209102143508","type":0,"content":"I'm running a local port-forwarded docker image of PGVector, pulled from ankane/pgvector, but when I try to connect to it via my Jupyter Notebook I'm getting this error, any ideas why?\n\nsolved: issues with some username/password mismatches","channel_id":"1038097349660135474","author":{"id":"252785953687470080","username":"ARandomPerson07","global_name":null,"avatar":"81320f554bd416f6a9954813aec39846","discriminator":"0980","public_flags":64,"avatar_decoration":null},"attachments":[{"id":"1116264208812748850","filename":"image.png","size":14373,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1116264208812748850/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1116264208812748850/image.png","width":1218,"height":113,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T07:15:26.636000+00:00","edited_timestamp":"2023-06-08T08:59:41.906000+00:00","flags":0,"components":[]},{"id":"1116249517906464768","type":0,"content":"as tends to be the case in machine learning, alot of it is that meme where you just tell the language model to do stuff and it \"draws the rest of the owl\"","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:17:03.982000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116249219838267453","type":0,"content":"There's some connecting ideas with the parsing the output as well depending on how you set things up, I think there's a good overview here <https://www.youtube.com/watch?v=UVn2NroKQCw>","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:15:52.917000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116248788676378624","type":0,"content":"the technical part of ReAct is sort of difficult to describe, I don't think the paper does a good job but I'm not sure how to put things any differently","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:14:10.120000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116248497688170546","type":0,"content":"","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1116248497491017738","filename":"image.png","size":77984,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1116248497491017738/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1116248497491017738/image.png","width":884,"height":626,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:13:00.743000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116248455925469255","type":0,"content":"> I'm benchmarking a large language models abilities to translate from japanese to english, could you give me a list of 25 commonly mistranslated japanese phrases in full sentences and their english counterparts, provided as a JSON object like this\n> {\n> Japanese: \"これは\"\n> English: \"This is\"\n> }","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:12:50.786000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116248427433578556","type":19,"content":"There's two parts going on, you're likely using ReAct framework <https://arxiv.org/pdf/2210.03629.pdf> \nEverything else is basically just structuring prompts to get the language model to spit out what you wanted, for example with chat gpt:","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"787705681574625310","username":"Skittle","avatar":"e0c155503c4526f2d059bdfd9951ef5d","discriminator":"3972","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:12:43.993000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116245459799904298"},"referenced_message":{"id":"1116245459799904298","type":0,"content":"Hello, I am learning about tools and agents in Langchain. I understand that tool is just a function which you can call using Natural Language. What I don't understand is how is this happening, like what's under the hood that is able to convert Natural language to proper parameters that can be passed to a function. Is it just the output parser or there is something more. Something to do with the function documentations or API documentation in case the function is an API call. It would be really helpful if someone can clarify this doubt or can link some blog or video which explains this concept in depth. Thank You","channel_id":"1038097349660135474","author":{"id":"787705681574625310","username":"Skittle","global_name":null,"avatar":"e0c155503c4526f2d059bdfd9951ef5d","discriminator":"3972","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:00:56.454000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116245459799904298","type":0,"content":"Hello, I am learning about tools and agents in Langchain. I understand that tool is just a function which you can call using Natural Language. What I don't understand is how is this happening, like what's under the hood that is able to convert Natural language to proper parameters that can be passed to a function. Is it just the output parser or there is something more. Something to do with the function documentations or API documentation in case the function is an API call. It would be really helpful if someone can clarify this doubt or can link some blog or video which explains this concept in depth. Thank You","channel_id":"1038097349660135474","author":{"id":"787705681574625310","username":"Skittle","global_name":null,"avatar":"e0c155503c4526f2d059bdfd9951ef5d","discriminator":"3972","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T06:00:56.454000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116230320438644777","type":0,"content":"Hello everyone\nCan anyone guide me on how I can stream tokens using langchain.","channel_id":"1038097349660135474","author":{"id":"1115950718889766952","username":"gaggi_72","global_name":null,"avatar":null,"discriminator":"9667","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T05:00:46.949000+00:00","edited_timestamp":"2023-06-08T05:04:33.091000+00:00","flags":0,"components":[]},{"id":"1116219744203321384","type":0,"content":"Hey does anyone know how to add multiple retrivers in chain? like one retriver that will store our custom knowledgebase and the other openai retriver that will use openai knowledge base","channel_id":"1038097349660135474","author":{"id":"1077099657110495283","username":"juzarantri","global_name":null,"avatar":"4300ac4ab8d80e1211857b46c0c52e1b","discriminator":"3474","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T04:18:45.378000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116209611377217536","type":0,"content":"👍","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T03:38:29.524000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116209371454648341","type":0,"content":"ty!!","channel_id":"1038097349660135474","author":{"id":"875067761557127178","username":"gautam","global_name":null,"avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T03:37:32.322000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116209362139107459","type":19,"content":"actually i think i figured it out","channel_id":"1038097349660135474","author":{"id":"875067761557127178","username":"gautam","global_name":null,"avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"943884739713060906","username":"TPsilly","avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T03:37:30.101000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116207158573412442"},"referenced_message":{"id":"1116207158573412442","type":19,"content":"","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1116207158414024714","filename":"image.png","size":14829,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1116207158414024714/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1116207158414024714/image.png","width":372,"height":160,"content_type":"image/png"}],"embeds":[],"mentions":[{"id":"875067761557127178","username":"gautam","avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"flags":4194304,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T03:28:44.730000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116199826707726437"}}},{"id":"1116207242111369346","type":0,"content":"also have u had exp with memory classes?","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T03:29:04.647000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116207184343208085","type":0,"content":"when creating an chain/agent","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T03:28:50.874000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116207158573412442","type":19,"content":"","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1116207158414024714","filename":"image.png","size":14829,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1116207158414024714/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1116207158414024714/image.png","width":372,"height":160,"content_type":"image/png"}],"embeds":[],"mentions":[{"id":"875067761557127178","username":"gautam","avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"flags":4194304,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T03:28:44.730000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116199826707726437"},"referenced_message":{"id":"1116199826707726437","type":0,"content":"don't see an option called \"verbose\", where should I set it? <@943884739713060906>","channel_id":"1038097349660135474","author":{"id":"875067761557127178","username":"gautam","global_name":null,"avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"943884739713060906","username":"TPsilly","avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:59:36.677000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116200789539561472","type":0,"content":"will have to give this one a shot too 👍","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T03:03:26.234000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116200682698059866","type":19,"content":"ah, looks like I'm not remembering correctly, can do a few \n> Falcon-40B is trained mostly on English, German, Spanish, French, with limited capabilities also in in Italian, Portuguese, Polish, Dutch, Romanian, Czech, Swedish.","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T03:03:00.761000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116198184130187284"},"referenced_message":{"id":"1116198184130187284","type":0,"content":"could do CPU inference on it but I think for specifically translation purposes it was trained on only english IIRC","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:53:05.056000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116199826707726437","type":0,"content":"don't see an option called \"verbose\", where should I set it? <@943884739713060906>","channel_id":"1038097349660135474","author":{"id":"875067761557127178","username":"gautam","global_name":null,"avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"943884739713060906","username":"TPsilly","avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:59:36.677000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116199313605931088","type":0,"content":"ok will try","channel_id":"1038097349660135474","author":{"id":"875067761557127178","username":"gautam","global_name":null,"avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:57:34.344000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116199257813291079","type":0,"content":"Set verbose to true and see more","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:57:21.042000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116199215455027241","type":0,"content":"<@875067761557127178> maybe the context from the chain and/or history is becoming too long?","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"875067761557127178","username":"gautam","avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"flags":4194304,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:57:10.943000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116198266904776785","type":0,"content":"My call to embeddings API is failing because text is too long, don't know why. \n\nAll my docs are under 2,000 characters yet I have an OpenAI embeddings api request going for more than 3million characters failing obviously. I dont understand why this happens, how can I prevent this?\n\nI know im doing some beginner mistake 😭 \n```js\nawait PineconeStore.fromTexts(\n    docs,\n    docs.map((doc,i) => {return {id: i+1}}),\n    new OpenAIEmbeddings({\n      openAIApiKey: process.env.OPENAI_API_KEY\n    }),\n    {\n      pineconeIndex,\n    }\n  )\n```","channel_id":"1038097349660135474","author":{"id":"875067761557127178","username":"gautam","global_name":null,"avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:53:24.791000+00:00","edited_timestamp":"2023-06-08T02:53:31.438000+00:00","flags":0,"components":[]},{"id":"1116198184130187284","type":0,"content":"could do CPU inference on it but I think for specifically translation purposes it was trained on only english IIRC","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:53:05.056000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116198082187628644","type":0,"content":"40B is a really awkward size and I can't fit it 🤣","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:52:40.751000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116197998528045086","type":0,"content":"3090 TI atm, the 30B models on GGML take about 20K of the vram","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:52:20.805000+00:00","edited_timestamp":null,"flags":0,"components":[],"reactions":[{"emoji":{"id":null,"name":"❤️"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}]},{"id":"1116197898783301642","type":0,"content":"Is this the correct way to use OpenAI embeddings with Pinecone on LangchainJS? \n```js\nawait PineconeStore.fromTexts(\n    docs,\n    docs.map((doc,i) => {return {id: i+1}}),\n    new OpenAIEmbeddings({\n      openAIApiKey: process.env.OPENAI_API_KEY\n    }),\n    {\n      pineconeIndex,\n    }\n  )\n```","channel_id":"1038097349660135474","author":{"id":"875067761557127178","username":"gautam","global_name":null,"avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:51:57.024000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116197887685185547","type":0,"content":"Hello everyone! Is there any way to just generate prompt with langchain other than chat with llm?","channel_id":"1038097349660135474","author":{"id":"1050712454671380490","username":"Gaze","global_name":null,"avatar":"cdfe36f4cfbf5890f9378e292902c25b","discriminator":"3607","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:51:54.378000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116197828788752485","type":0,"content":"Nice, what card? Falcon 40b claims to be the best, I haven't fired it up yet","channel_id":"1038097349660135474","author":{"id":"971602465323642922","username":"MrShiny","global_name":"Will Pride","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:51:40.336000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116197634642808883","type":0,"content":"own hardware","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:50:54.048000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116197371819343904","type":19,"content":"Are you running on your own hardware or hosted somewhere?","channel_id":"1038097349660135474","author":{"id":"971602465323642922","username":"MrShiny","global_name":"Will Pride","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"229576111212855296","username":"coffeevampir3","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"Coffee Vampire","avatar_decoration":null,"display_name":"Coffee Vampire","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:49:51.386000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116189975004848331"},"referenced_message":{"id":"1116189975004848331","type":0,"content":"yeah I think that bar is too high, I'm using a Llama 30B model right now and it's maybe a 6-7/10. Suprisingly not alot of purpose made translation models, might try qlora'ing one","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:20:27.848000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116192860065235096","type":0,"content":"My call to embeddings API is failing because text is too long, don't know why. https://github.com/hwchase17/langchainjs/issues/1581","channel_id":"1038097349660135474","author":{"id":"875067761557127178","username":"gautam","global_name":null,"avatar":"008933f884b722ddd0427b7c18e51940","discriminator":"1081","public_flags":4194304,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchainjs/issues/1581","title":"Request to OpenAI Embeddings too long  · Issue #1581 · hwchase17/la...","description":"I have a list of long pdfs (20+) which I want to use in Pinecone DB. I have used some code to convert them into .txt files. Now here is the code that is supposed to split them into chunks and feed ...","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/1f18206c58866d46d43fb3f8334bc0f96bd8e291bd831ed8253b816a96a06c44/hwchase17/langchainjs/issues/1581","proxy_url":"https://images-ext-2.discordapp.net/external/UcM-Ij9uX4XhWCfNgM7o-fJhnbiUngOKUz-Er69Uxu0/https/opengraph.githubassets.com/1f18206c58866d46d43fb3f8334bc0f96bd8e291bd831ed8253b816a96a06c44/hwchase17/langchainjs/issues/1581","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:31:55.700000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116191826169298994","type":0,"content":"thanks, i am on 3.8.1 right now","channel_id":"1038097349660135474","author":{"id":"213843294701092865","username":"tangylisa","global_name":"TangyLisa","avatar":"d54c92e8e946ea295bfaa40ae38dbfc6","discriminator":"0","public_flags":64,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:27:49.200000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116191783492259890","type":0,"content":"can go newer but more and more likely to break","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:27:39.025000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116191625467670588","type":0,"content":"3.10 is the safest, 3.11 broke some things for many libraries","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:27:01.349000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116191508148793464","type":0,"content":"which version of python is the best to use langchain with? im having installation issues","channel_id":"1038097349660135474","author":{"id":"213843294701092865","username":"tangylisa","global_name":"TangyLisa","avatar":"d54c92e8e946ea295bfaa40ae38dbfc6","discriminator":"0","public_flags":64,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:26:33.378000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116190731539853312","type":0,"content":"oh I haven't had mirostat on, maybe I should hold my tongue and actually configure things correctly first","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:23:28.220000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116190378165551235","type":0,"content":"Some of these local models are super suprising though, so I'm also in for being proven wrong xD","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:22:03.969000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116189975004848331","type":0,"content":"yeah I think that bar is too high, I'm using a Llama 30B model right now and it's maybe a 6-7/10. Suprisingly not alot of purpose made translation models, might try qlora'ing one","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:20:27.848000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116188818471661699","type":0,"content":"My understanding is that GPT-4 is currently unbeatably good, and my limited experience with other models confirms that. Want to be proven wrong though.","channel_id":"1038097349660135474","author":{"id":"971602465323642922","username":"MrShiny","global_name":"Will Pride","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:15:52.109000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116188004063641673","type":0,"content":"Anyone experimented with (local) models for neural translation? Gpt-4 seems basically unbeatably good, I've tried a handful of models mostly based on Llama and I'm not super impressed.","channel_id":"1038097349660135474","author":{"id":"229576111212855296","username":"coffeevampir3","global_name":"Coffee Vampire","avatar":"303d86ba731d14668c4b46b6dae38ef9","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T02:12:37.939000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116180477225738251","type":0,"content":"can anyone tell me what im doing wrong?\nhttps://github.com/hwchase17/langchain/discussions/5828","channel_id":"1038097349660135474","author":{"id":"138231684456775680","username":"kylegrande","global_name":"Kyle","avatar":"ca734508936596d3519135352a7bab1a","discriminator":"0","public_flags":64,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchain/discussions/5828","title":"Agent Not Using Observation's from one Tool for another Tool · hwch...","description":"So I have a few PromptTemplates tied to an LLMChain as tools for my agent, however, as the agent uses the tools it only ever uses the context of the agent.run('a_context\") create_b_context...","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/e1b4230c6317424c737d44f5cb89e3abbb955c4103535cf4469856c215d85d0f/hwchase17/langchain/discussions/5828","proxy_url":"https://images-ext-1.discordapp.net/external/P5ZfXXIzf2ClGlmdvy3AXswgWP6dwGLrKRdiQNgMyXQ/https/opengraph.githubassets.com/e1b4230c6317424c737d44f5cb89e3abbb955c4103535cf4469856c215d85d0f/hwchase17/langchain/discussions/5828","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T01:42:43.401000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116162364950196254","type":0,"content":"jupyter notebook < VSCode < virtualenv < python is runtime insanity","channel_id":"1038097349660135474","author":{"id":"971602465323642922","username":"MrShiny","global_name":"Will Pride","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T00:30:45.098000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116162029124853780","type":0,"content":"ty <@971602465323642922>","channel_id":"1038097349660135474","author":{"id":"734658681756581898","username":"jbx","global_name":null,"avatar":"2b23f162a784dfc7afe4644e891c5934","discriminator":"2239","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"971602465323642922","username":"MrShiny","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"Will Pride","avatar_decoration":null,"display_name":"Will Pride","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T00:29:25.031000+00:00","edited_timestamp":null,"flags":0,"components":[],"reactions":[{"emoji":{"id":null,"name":"👍"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}]},{"id":"1116161745455697941","type":0,"content":"checkout https://github.com/hwchase17/langchain/issues/3894","channel_id":"1038097349660135474","author":{"id":"971602465323642922","username":"MrShiny","global_name":"Will Pride","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchain/issues/3894","title":"TrajectoryEvalChain import error -  cannot import name 'ChainManage...","description":"I am trying to follow this guide on evaluation of agents (https://python.langchain.com/en/latest/use_cases/evaluation/generic_agent_evaluation.html), but I'm seeing the following error: ImportE...","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/1fe50b222b3da61887bc3979a0d87193d12bed00ca7a9dff339bbf07b685d741/hwchase17/langchain/issues/3894","proxy_url":"https://images-ext-2.discordapp.net/external/Ol1mh8BGsZ_gkn9pp6CAETvgkvvG4mx2jdLQUmZlgJk/https/opengraph.githubassets.com/1fe50b222b3da61887bc3979a0d87193d12bed00ca7a9dff339bbf07b685d741/hwchase17/langchain/issues/3894","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T00:28:17.399000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116160150349295646","type":0,"content":"is there an import im missing or is this some other issue?","channel_id":"1038097349660135474","author":{"id":"734658681756581898","username":"jbx","global_name":null,"avatar":"2b23f162a784dfc7afe4644e891c5934","discriminator":"2239","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T00:21:57.096000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116160060255645758","type":0,"content":"top of error msg: \"\"\"ImportError                               Traceback (most recent call last)\nCell In[12], line 3\n      1 from langchain.chains import SimpleSequentialChain\n      2 from langchain.llms import OpenAI\n----> 3 from langchain.chat_models import ChatOpenAI\n      4 from langchain.chains import LLMChain\n      5 from langchain.prompts import PromptTemplate\n\nFile ~/langchain_stuff/.venv/lib/python3.9/site-packages/langchain/chat_models/__init__.py:1\n----> 1 from langchain.chat_models.anthropic import ChatAnthropic\n      2 from langchain.chat_models.azure_openai import AzureChatOpenAI\n      3 from langchain.chat_models.google_palm import ChatGooglePalm\n\nFile ~/langchain_stuff/.venv/lib/python3.9/site-packages/langchain/chat_models/anthropic.py:5\n      1 from typing import Any, Dict, List, Optional\n      3 from pydantic import Extra\n----> 5 from langchain.callbacks.manager import (\n      6     AsyncCallbackManagerForLLMRun,\n      7     CallbackManagerForLLMRun,\n      8 )\n      9 from langchain.chat_models.base import BaseChatModel\n     10 from langchain.llms.anthropic import _AnthropicCommon\"\"\"","channel_id":"1038097349660135474","author":{"id":"734658681756581898","username":"jbx","global_name":null,"avatar":"2b23f162a784dfc7afe4644e891c5934","discriminator":"2239","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T00:21:35.616000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116160001204039771","type":0,"content":"dumb q but im getting this error after upgrading and trying to follow simple tutorial on site: ImportError: cannot import name 'ChainManagerMixin' from 'langchain.callbacks.base' (/Users/jawaun/langchain_stuff/.venv/lib/python3.9/site-packages/langchain/callbacks/base.py)","channel_id":"1038097349660135474","author":{"id":"734658681756581898","username":"jbx","global_name":null,"avatar":"2b23f162a784dfc7afe4644e891c5934","discriminator":"2239","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T00:21:21.537000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116158810235609130","type":0,"content":"is there any way to fix that?","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T00:16:37.588000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116158776874111040","type":0,"content":"so i am running 2 chains on a single chat using the same memory, but it breaks the code","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T00:16:29.634000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116158695781433365","type":0,"content":"hi","channel_id":"1038097349660135474","author":{"id":"943884739713060906","username":"TPsilly","global_name":null,"avatar":"6d1fcd62545041f0afcdec368cc2b15c","discriminator":"8648","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-08T00:16:10.300000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116141232360525955","type":0,"content":"`temperature=0` is fine, this just tells the LLM to be \"boring\" instead of \"creative\". This code is behaving correctly; the model isn't logging anything because there's no `verbose=True` and the result is not being printed.","channel_id":"1038097349660135474","author":{"id":"971602465323642922","username":"MrShiny","global_name":"Will Pride","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T23:06:46.696000+00:00","edited_timestamp":"2023-06-07T23:07:32.171000+00:00","flags":0,"components":[]},{"id":"1116139800605511740","type":19,"content":"Hey, try increasing the temperature. It is not doing anything maybe because temperature is 0.","channel_id":"1038097349660135474","author":{"id":"1062863913034715156","username":"AIexplorer","global_name":null,"avatar":null,"discriminator":"7955","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"540832307133546496","username":"Dimanche","avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T23:01:05.339000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115830726139576365"},"referenced_message":{"id":"1115830726139576365","type":0,"content":"hey, i'm struggling with chat messages, can someone help?\n```python\nfrom dotenv import load_dotenv\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    SystemMessagePromptTemplate,\n    AIMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n)\nfrom langchain.schema import (\n    AIMessage,\n    HumanMessage,\n    SystemMessage\n)\n\n\nload_dotenv()\nimport os\nopenai_key = os.getenv(\"OPENAI_API_KEY\")\n\nchat = ChatOpenAI(temperature=0)\n\n# Initialize a conversation\nchat(\n    [\n        chat([HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")])\n    ]\n```\nIt does nothing.","channel_id":"1038097349660135474","author":{"id":"540832307133546496","username":"Dimanche","global_name":null,"avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1115830725879533628","filename":"image.png","size":23211,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1115830725879533628/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1115830725879533628/image.png","width":974,"height":125,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:32:56.244000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116136136935477258","type":19,"content":"Based on your install path it doesn't look like you're using a `conda` env, maybe try using one?","channel_id":"1038097349660135474","author":{"id":"971602465323642922","username":"MrShiny","global_name":"Will Pride","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"401724703888375811","username":"Bulletz4Breakfast","avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T22:46:31.852000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116124832455720960"},"referenced_message":{"id":"1116124832455720960","type":19,"content":"I did, I even checked the version and it was the latest one. Any ideas on how to get around this annoying error?","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1116010291847757874","username":"chriscos","avatar":"f7f2e9361e8a54ce6e72580ac7b967af","discriminator":"1023","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T22:01:36.654000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116106778858496060"}}},{"id":"1116124832455720960","type":19,"content":"I did, I even checked the version and it was the latest one. Any ideas on how to get around this annoying error?","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1116010291847757874","username":"chriscos","avatar":"f7f2e9361e8a54ce6e72580ac7b967af","discriminator":"1023","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T22:01:36.654000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116106778858496060"},"referenced_message":{"id":"1116106778858496060","type":19,"content":"Did you try adding the pip install commands at the top of the notebook?","channel_id":"1038097349660135474","author":{"id":"1116010291847757874","username":"chriscos","global_name":null,"avatar":"f7f2e9361e8a54ce6e72580ac7b967af","discriminator":"1023","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"401724703888375811","username":"Bulletz4Breakfast","avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T20:49:52.341000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116028716418617395"}}},{"id":"1116110947287846982","type":19,"content":"aha - beautiful. Thanks. I will give it a shot","channel_id":"1038097349660135474","author":{"id":"1109905758453239848","username":"Goo","global_name":null,"avatar":null,"discriminator":"0633","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"971602465323642922","username":"MrShiny","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"Will Pride","avatar_decoration":null,"display_name":"Will Pride","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T21:06:26.172000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116107466946646126"},"reactions":[{"emoji":{"id":null,"name":"👍"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}],"referenced_message":{"id":"1116107466946646126","type":19,"content":"I think the blessed way to do this would be to use a router chain that parses the input and determines whether to use your business logic chain or the general answer chain https://python.langchain.com/en/latest/modules/chains/generic/router.html","channel_id":"1038097349660135474","author":{"id":"971602465323642922","username":"MrShiny","global_name":"Will Pride","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1109905758453239848","username":"Goo","avatar":null,"discriminator":"0633","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T20:52:36.394000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116099253132083241"}}},{"id":"1116107466946646126","type":19,"content":"I think the blessed way to do this would be to use a router chain that parses the input and determines whether to use your business logic chain or the general answer chain https://python.langchain.com/en/latest/modules/chains/generic/router.html","channel_id":"1038097349660135474","author":{"id":"971602465323642922","username":"MrShiny","global_name":"Will Pride","avatar":"66ac15dff97c7eea4d5138b346672489","discriminator":"3192","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1109905758453239848","username":"Goo","avatar":null,"discriminator":"0633","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T20:52:36.394000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116099253132083241"},"referenced_message":{"id":"1116099253132083241","type":0,"content":"Is it possible to let the langchain agent to answer an unseen type of question with its own knowledge from pre-trained weights instead of following the predefined chain of thought? For example, the prompt template that I have engineered is for math problem solving. But I also want the agent to answer questions such as \"Who is Albert Einstein\" or \"who introduced quantan physics\". Instead of following the path that I have previously defined in my prompt template, I want the agent just to complete the answer. I have raised an issue on github too. More details can be found here https://github.com/hwchase17/langchain/issues/5857","channel_id":"1038097349660135474","author":{"id":"1109905758453239848","username":"Goo","global_name":null,"avatar":null,"discriminator":"0633","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchain/issues/5857","title":"Issue: What if I want the langchain agent to answer an unseen type ...","description":"Issue you'd like to raise. Hi - I built a langchain agent to solve business analytics problems. I gave it a bunch of examples in the prompt template about how to solve those problem and send it...","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/c374bc60864f919b7513fde8cd418e0bde73daa21f8187994f72d89243ecb3e4/hwchase17/langchain/issues/5857","proxy_url":"https://images-ext-2.discordapp.net/external/-ObeuErnyaEMhrAdMmv2zZ5zliYuyY6-z5EM7DAzyno/https/opengraph.githubassets.com/c374bc60864f919b7513fde8cd418e0bde73daa21f8187994f72d89243ecb3e4/hwchase17/langchain/issues/5857","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T20:19:58.068000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116107139249868830","type":19,"content":"yee eventually got it right, thanks, i'm new to langchain","channel_id":"1038097349660135474","author":{"id":"540832307133546496","username":"Dimanche","global_name":null,"avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"236369011179388929","username":"evylz","avatar":"b351db3bd64daf24dc8804b5b2be2324","discriminator":"0","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":"Evylz","avatar_decoration":null,"display_name":"Evylz","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T20:51:18.265000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116106947712786462"},"referenced_message":{"id":"1116106947712786462","type":19,"content":"You are not printing anything and don't have the chat set to verbose. Adding either should help you see output","channel_id":"1038097349660135474","author":{"id":"236369011179388929","username":"evylz","global_name":"Evylz","avatar":"b351db3bd64daf24dc8804b5b2be2324","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"540832307133546496","username":"Dimanche","avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T20:50:32.599000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115830726139576365"}}},{"id":"1116106947712786462","type":19,"content":"You are not printing anything and don't have the chat set to verbose. Adding either should help you see output","channel_id":"1038097349660135474","author":{"id":"236369011179388929","username":"evylz","global_name":"Evylz","avatar":"b351db3bd64daf24dc8804b5b2be2324","discriminator":"0","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"540832307133546496","username":"Dimanche","avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T20:50:32.599000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115830726139576365"},"referenced_message":{"id":"1115830726139576365","type":0,"content":"hey, i'm struggling with chat messages, can someone help?\n```python\nfrom dotenv import load_dotenv\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    SystemMessagePromptTemplate,\n    AIMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n)\nfrom langchain.schema import (\n    AIMessage,\n    HumanMessage,\n    SystemMessage\n)\n\n\nload_dotenv()\nimport os\nopenai_key = os.getenv(\"OPENAI_API_KEY\")\n\nchat = ChatOpenAI(temperature=0)\n\n# Initialize a conversation\nchat(\n    [\n        chat([HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")])\n    ]\n```\nIt does nothing.","channel_id":"1038097349660135474","author":{"id":"540832307133546496","username":"Dimanche","global_name":null,"avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1115830725879533628","filename":"image.png","size":23211,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1115830725879533628/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1115830725879533628/image.png","width":974,"height":125,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:32:56.244000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116106778858496060","type":19,"content":"Did you try adding the pip install commands at the top of the notebook?","channel_id":"1038097349660135474","author":{"id":"1116010291847757874","username":"chriscos","global_name":null,"avatar":"f7f2e9361e8a54ce6e72580ac7b967af","discriminator":"1023","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"401724703888375811","username":"Bulletz4Breakfast","avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T20:49:52.341000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116028716418617395"},"referenced_message":{"id":"1116028716418617395","type":0,"content":"Hey guys.. my Jupyter notebook and even VS Code does not recognise Langchain installed","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T15:39:40.805000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116099253132083241","type":0,"content":"Is it possible to let the langchain agent to answer an unseen type of question with its own knowledge from pre-trained weights instead of following the predefined chain of thought? For example, the prompt template that I have engineered is for math problem solving. But I also want the agent to answer questions such as \"Who is Albert Einstein\" or \"who introduced quantan physics\". Instead of following the path that I have previously defined in my prompt template, I want the agent just to complete the answer. I have raised an issue on github too. More details can be found here https://github.com/hwchase17/langchain/issues/5857","channel_id":"1038097349660135474","author":{"id":"1109905758453239848","username":"Goo","global_name":null,"avatar":null,"discriminator":"0633","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"article","url":"https://github.com/hwchase17/langchain/issues/5857","title":"Issue: What if I want the langchain agent to answer an unseen type ...","description":"Issue you'd like to raise. Hi - I built a langchain agent to solve business analytics problems. I gave it a bunch of examples in the prompt template about how to solve those problem and send it...","color":1975079,"provider":{"name":"GitHub"},"thumbnail":{"url":"https://opengraph.githubassets.com/c374bc60864f919b7513fde8cd418e0bde73daa21f8187994f72d89243ecb3e4/hwchase17/langchain/issues/5857","proxy_url":"https://images-ext-2.discordapp.net/external/-ObeuErnyaEMhrAdMmv2zZ5zliYuyY6-z5EM7DAzyno/https/opengraph.githubassets.com/c374bc60864f919b7513fde8cd418e0bde73daa21f8187994f72d89243ecb3e4/hwchase17/langchain/issues/5857","width":1200,"height":600}}],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T20:19:58.068000+00:00","edited_timestamp":null,"flags":0,"components":[],"reactions":[{"emoji":{"id":null,"name":"❓"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}]},{"id":"1116048825468072027","type":19,"content":"I don’t have any such file yet getting the error","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"138231684456775680","username":"kylegrande","avatar":"ca734508936596d3519135352a7bab1a","discriminator":"0","public_flags":64,"flags":64,"banner":null,"accent_color":null,"global_name":"Kyle","avatar_decoration":null,"display_name":"Kyle","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T16:59:35.176000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116040525619933255"},"referenced_message":{"id":"1116040525619933255","type":19,"content":"had this problem cause i named my file langchain.py lmao","channel_id":"1038097349660135474","author":{"id":"138231684456775680","username":"kylegrande","global_name":"Kyle","avatar":"ca734508936596d3519135352a7bab1a","discriminator":"0","public_flags":64,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"401724703888375811","username":"Bulletz4Breakfast","avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T16:26:36.338000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116029196108582952"}}},{"id":"1116048484550836224","type":0,"content":"im creating an app that is heavily tool based, im using agent CHAT_ZERO_SHOT_REACT_DESCRIPTION, but I`m not being able to use memory with it, is that right? when i say my name and later ask my name the bot doesnt remember, what can I do to use CHAT_ZERO_SHOT_REACT_DESCRIPTION with memory?","channel_id":"1038097349660135474","author":{"id":"978269959631302666","username":"Daniel Becker","global_name":null,"avatar":"016b5bbf0f142e5ceb96f64421ce378f","discriminator":"0760","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T16:58:13.895000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116046772817633410","type":0,"content":"Can I use prompts when querying an api using create_openapi_agent? I would like to add some more context to the queries sent to the api, without having to include it every time.","channel_id":"1038097349660135474","author":{"id":"404019139473047554","username":"hazard567","global_name":null,"avatar":null,"discriminator":"0664","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T16:51:25.786000+00:00","edited_timestamp":"2023-06-07T16:52:44.636000+00:00","flags":0,"components":[]},{"id":"1116040525619933255","type":19,"content":"had this problem cause i named my file langchain.py lmao","channel_id":"1038097349660135474","author":{"id":"138231684456775680","username":"kylegrande","global_name":"Kyle","avatar":"ca734508936596d3519135352a7bab1a","discriminator":"0","public_flags":64,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"401724703888375811","username":"Bulletz4Breakfast","avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T16:26:36.338000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116029196108582952"},"referenced_message":{"id":"1116029196108582952","type":0,"content":"Using a Mac","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T15:41:35.172000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116029196108582952","type":0,"content":"Using a Mac","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T15:41:35.172000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116029163598520391","type":0,"content":"Anybody able to solve this?","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T15:41:27.421000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116028851127079013","type":0,"content":"This is the error I get","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1116028850871214232","filename":"Screenshot_2023-06-07_at_9.10.04_PM.png","size":359586,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1116028850871214232/Screenshot_2023-06-07_at_9.10.04_PM.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1116028850871214232/Screenshot_2023-06-07_at_9.10.04_PM.png","width":1540,"height":1260,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T15:40:12.922000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116028734466699324","type":0,"content":"","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1116028734181478540","filename":"Screenshot_2023-06-07_at_9.08.56_PM.png","size":192639,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1116028734181478540/Screenshot_2023-06-07_at_9.08.56_PM.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1116028734181478540/Screenshot_2023-06-07_at_9.08.56_PM.png","width":1098,"height":1016,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T15:39:45.108000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116028716418617395","type":0,"content":"Hey guys.. my Jupyter notebook and even VS Code does not recognise Langchain installed","channel_id":"1038097349660135474","author":{"id":"401724703888375811","username":"Bulletz4Breakfast","global_name":null,"avatar":"155c60e90a2496190ace8d1bdea6e4a9","discriminator":"0312","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T15:39:40.805000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116021095171100744","type":19,"content":"I simply need to ask the question “out loud” to figure it out 😀.   requests=Requests(headers={ … })","channel_id":"1038097349660135474","author":{"id":"1116010291847757874","username":"chriscos","global_name":null,"avatar":"f7f2e9361e8a54ce6e72580ac7b967af","discriminator":"1023","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T15:09:23.758000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1116013585810853971"},"referenced_message":{"id":"1116013585810853971","type":0,"content":"Hi, I am trying to call an API with APIoperation.from_openapi_spec. I need to provide two headers with the request: Authorization and appkey.  How can I add these headers to the request?","channel_id":"1038097349660135474","author":{"id":"1116010291847757874","username":"chriscos","global_name":null,"avatar":"f7f2e9361e8a54ce6e72580ac7b967af","discriminator":"1023","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T14:39:33.387000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1116013585810853971","type":0,"content":"Hi, I am trying to call an API with APIoperation.from_openapi_spec. I need to provide two headers with the request: Authorization and appkey.  How can I add these headers to the request?","channel_id":"1038097349660135474","author":{"id":"1116010291847757874","username":"chriscos","global_name":null,"avatar":"f7f2e9361e8a54ce6e72580ac7b967af","discriminator":"1023","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T14:39:33.387000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1116010760221507736","type":0,"content":"Hi, has someone sucessfully achieved a prompt template for answering in markdown? I am specifying to display answer in markdown, but it never is","channel_id":"1038097349660135474","author":{"id":"376809451044470785","username":"Ziigaa","global_name":null,"avatar":"92db54d6a0cfb151255c4fcc16ce9c9e","discriminator":"7727","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T14:28:19.714000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115986290672934992","type":0,"content":"Hey, I'm having some issues with my agent carrying over context from one tool to another.\nhttps://github.com/hwchase17/langchain/discussions/5828#discussion-5273940\nSo I have a few PromptTemplates tied to an LLMChain as tools for my agent, however, as the agent uses the tools it only ever uses the context of the agent.run('a_context\")\n```python\ncreate_b_context = PromptTemplate(\n    input_variables=[\"user_input\"],\n    template=\"Create some b context using {user_input}\"\n    )\ncreate_c_context = PromptTemplate(\n    input_variables=[\"user_input\"],\n    template=\"Create some b context using {user_input}\"\n    )\n\nllm = OpenAI(openai_api_key=api_key)\nllm = OpenAI(temperature=0.9)\n\nchain_create_b_context= LLMChain(llm=llm, prompt=create_c_context)\nchain_create_c_context = LLMChain(llm=llm, prompt=create_c_context)\n\ntools = [\n    Tool(\n        name = 'create_b_context_tool',\n        func=chain_create_b_context.run,\n        description=\"Create B Context\",\n        ),\n    Tool(\n        name = 'create_c_context_tool',\n        func=chain_create_c_context.run,\n        description=\"Create C context using B Context\",\n        ),\n]\n\nagent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n\nagent.run(\"A context\")\n```\n\nThe output is usually something like:\n```terminal\nI need B and C Context\nAction: create_b_context\nAction Input: A Context\nObservation: Context B\nThought: I have B, now I need C\nAction: create_c_context\nAction Input: A Context\n```","channel_id":"1038097349660135474","author":{"id":"138231684456775680","username":"kylegrande","global_name":"Kyle","avatar":"ca734508936596d3519135352a7bab1a","discriminator":"0","public_flags":64,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T12:51:05.719000+00:00","edited_timestamp":null,"flags":4,"components":[],"reactions":[{"emoji":{"id":null,"name":"👍"},"count":1,"count_details":{"burst":0,"normal":1},"burst_colors":[],"me_burst":false,"me":false,"burst_count":0}]},{"id":"1115984477861204049","type":0,"content":"I have a large text that I want to summarize using the load_summarize_chain map_reduce type. However, I found that the text is still too large after the reduce stage, exceeding the token limit. How can I generally solve this problem?","channel_id":"1038097349660135474","author":{"id":"1090515885007052871","username":"ericgogogo","global_name":null,"avatar":null,"discriminator":"6811","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T12:43:53.511000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115977393434263573","type":0,"content":"```from fastapi import FastAPI, WebSocket\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.llms import OpenAI\nfrom langchain.agents import load_tools, initialize_agent\nfrom langchain.agents import AgentType\n\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"\"\n\napp = FastAPI()\n\nllm = ChatOpenAI(temperature=0.0)\nmath_llm = OpenAI(temperature=0.0)\ntools = load_tools(\n    [\"human\", \"llm-math\"], \n    llm=math_llm,\n)\n\nagent_chain = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True,\n)\n\n@app.websocket(\"/ws\")\nasync def websocket_endpoint(websocket: WebSocket):\n    await websocket.accept()\n    while True:\n        data = await websocket.receive_text()\n        response = agent_chain.run(data)\n        await websocket.send_text(response)\n```\n\nI have a websocket for a basic agent, the agent uses human as a tool, what form does the input method of HumanInputRun (https://python.langchain.com/en/latest/modules/agents/tools/examples/human_tools.html#:~:text=By%20default%2C%20the%20HumanInputRun%20tool%20uses%20the%20python%20input%20function%20to%20get%20input%20from%20the%20user.) need to take for it to work with a websocket? The current form uses python input() which takes input from the terminal when the tool is called but I'd like to provide input through the UI just like the  the usual agent inputs.","channel_id":"1038097349660135474","author":{"id":"1058035792431288460","username":"Nas","global_name":null,"avatar":"9ae02501bd59d855f024bb880b1d5f4c","discriminator":"0875","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T12:15:44.452000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115948750733582396","type":0,"content":"Earlier, I thought it could be a RAM related the issue, but then I added 8 GB more to the system\n\nAnd I am running GGML models which are smaller than 4 GB in size","channel_id":"1038097349660135474","author":{"id":"1111481652191957054","username":"cryptoescobar","global_name":null,"avatar":"1628fc11e7961d85181295493426b775","discriminator":"6435","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T10:21:55.500000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115948406104395787","type":0,"content":"This is true with the two integrations I tried to load the LLMs locally i.e. gpt4all and llama-cpp-python","channel_id":"1038097349660135474","author":{"id":"1111481652191957054","username":"cryptoescobar","global_name":null,"avatar":"1628fc11e7961d85181295493426b775","discriminator":"6435","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T10:20:33.334000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115948318053388310","type":0,"content":"Hey there, I have been trying to build a chat UI using a UI library, but there's a problem whenever there's a long response from the LlmChain i.e. it reloads the model","channel_id":"1038097349660135474","author":{"id":"1111481652191957054","username":"cryptoescobar","global_name":null,"avatar":"1628fc11e7961d85181295493426b775","discriminator":"6435","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T10:20:12.341000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115942117630541895","type":0,"content":"Hi how can i use filters in qdrant as retriever? I know i can pass filters by \n\"retriever.search_kwargs['filter'] = query_filter\"\n but what is the value/structure of 'query_filter' suppose i want to match key with value?","channel_id":"1038097349660135474","author":{"id":"458856341897740310","username":"yashs","global_name":null,"avatar":null,"discriminator":"8846","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T09:55:34.045000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115926239207751750","type":0,"content":"Hey everyone, \nI'm stuck on an issue. I have made my own clickhouse agent closely copying the sql agent (https://python.langchain.com/en/latest/modules/agents/toolkits/examples/sql_database.html). It is working fine but I want the OpenAI llm to use gpt-4 instead of 'text-davinci-003' which is the default. 'text-davinci-003' only has 4k tokens and that is limiting us a lot.\n\n```\nagent_executor = create_clickhouse_agent(\n    # llm=ChatOpenAI(model_name=\"gpt-4\",streaming=True), # Could not parse LLM output errors\n    llm=OpenAI(model_name=\"gpt-4\", streaming=True, max_tokens=-1),\n    toolkit=toolkit,\n    verbose=True,\n    return_intermediate_steps=True,\n    top_k=20,\n)\n```\nThe OpenAI llm does not support GPT4 (or GPT 3.5) as it says they are chat models and when I use the ChatOpenAI as the llm, it runs but stops mid-chain with errors like the following \n```\nThought:Could not parse LLM output: `I see that the 'dist_events' table exists. Now, I should check the schema of the 'dist_events' table to understand what columns I can query.`\n```\nAny pointers or ideas??\n\nThanks in advance. I'm happy to anser any other questions as well","channel_id":"1038097349660135474","author":{"id":"1100744153186443357","username":"RamlahAziz","global_name":null,"avatar":null,"discriminator":"7770","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T08:52:28.334000+00:00","edited_timestamp":"2023-06-07T09:10:21.439000+00:00","flags":0,"components":[]},{"id":"1115923591901495386","type":0,"content":"Has anyone have used Weaviate Cloud Systems? I want to know about the pricing \"$0.050 per 1M vector dimensions stored \nor queried per month\"","channel_id":"1038097349660135474","author":{"id":"1078326467437531168","username":"jirpm","global_name":null,"avatar":null,"discriminator":"1547","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T08:41:57.167000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115891728336031744","type":0,"content":"Hey guys I manage to embed a pdf file into chunks using open embedding and now want to save the embeddings into the database so that I can semantic search from the database itself instead of re embedding from scratch and show the result. Please help me I am a beginner with AI","channel_id":"1038097349660135474","author":{"id":"406099219951124501","username":"nehatkhan786","global_name":null,"avatar":"03f70e147ffa1d6df23198532fb06c38","discriminator":"9937","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T06:35:20.301000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115889788977958962","type":0,"content":"i have the following use case : i want to have a knowledge base that is formed from 2 or more CSV files , with different schemes (different column names)\nto answer questions that are crossed the different csv data , i need to map between the different columns in different csv's.\nhow can i do this mapping ?\ni thought about creating additional mapping txt file , and have it as a tool used to get the mapping, but when it run it knows noghting about the csv's...\ndo i have option to do it in sequence ? like : \n1. look for the mapping\n2. get the csv's scheme\n3. map the columns to be with the same names\n4. join the csv's data according to the common columns\n5. answer the question","channel_id":"1038097349660135474","author":{"id":"1061886480974352394","username":"yoyotheone","global_name":null,"avatar":null,"discriminator":"4786","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T06:27:37.922000+00:00","edited_timestamp":"2023-06-07T06:30:32.993000+00:00","flags":0,"components":[]},{"id":"1115868434652213278","type":0,"content":"How can you use the SQLDatabase chain for one particular schema when you have 5+?","channel_id":"1038097349660135474","author":{"id":"235135294070980608","username":"HelloThisIsASH","global_name":null,"avatar":"b93772a87fdbe5ae8360ef08e548ec85","discriminator":"3068","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T05:02:46.654000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115832717091799131","type":0,"content":"<@540832307133546496> Also maybe try with just a single chat(message) call first instead of chat(chat(message)). And maybe add message.format_to_messages. Not sure the exact format call...","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"540832307133546496","username":"Dimanche","avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:40:50.924000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115832289608347719","type":0,"content":"<@540832307133546496> Try chat.run","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"540832307133546496","username":"Dimanche","avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:39:09.004000+00:00","edited_timestamp":"2023-06-07T02:39:20.636000+00:00","flags":0,"components":[]},{"id":"1115832112969420870","type":0,"content":"<@456404738947153922> Yes I believe so. From what I remeber reading the doc. You can ask the chat bot on their website this question and see what it says","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"456404738947153922","username":"amir⚡","avatar":"cbe2f57d6dc15093c77c33774e62b5ff","discriminator":"8041","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:38:26.890000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115832095932157992","type":0,"content":"well, it's actually the whole thing","channel_id":"1038097349660135474","author":{"id":"540832307133546496","username":"Dimanche","global_name":null,"avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:38:22.828000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115831866843480115","type":0,"content":"<@540832307133546496>  I think your code cut off","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"540832307133546496","username":"Dimanche","avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:37:28.209000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115831583857967175","type":0,"content":"Is it possible to use a conversational agent but swap in a custom llm for the chat portion of it?","channel_id":"1038097349660135474","author":{"id":"456404738947153922","username":"amir⚡","global_name":null,"avatar":"cbe2f57d6dc15093c77c33774e62b5ff","discriminator":"8041","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:36:20.740000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115830726139576365","type":0,"content":"hey, i'm struggling with chat messages, can someone help?\n```python\nfrom dotenv import load_dotenv\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    SystemMessagePromptTemplate,\n    AIMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n)\nfrom langchain.schema import (\n    AIMessage,\n    HumanMessage,\n    SystemMessage\n)\n\n\nload_dotenv()\nimport os\nopenai_key = os.getenv(\"OPENAI_API_KEY\")\n\nchat = ChatOpenAI(temperature=0)\n\n# Initialize a conversation\nchat(\n    [\n        chat([HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")])\n    ]\n```\nIt does nothing.","channel_id":"1038097349660135474","author":{"id":"540832307133546496","username":"Dimanche","global_name":null,"avatar":"3f683d1fbe2064782565061fe9d3c997","discriminator":"9827","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1115830725879533628","filename":"image.png","size":23211,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1115830725879533628/image.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1115830725879533628/image.png","width":974,"height":125,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:32:56.244000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115829127375761468","type":0,"content":"The issue I am facing is the ReadTheDocsLoader does not pick up any of the python code from the docs. Weird","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:26:35.069000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115828849163374672","type":0,"content":"Sadly the documentation is too large to convert to latex with sphinx. I am creating the html build and then going to try to covert that to pdf. If anyone has any idea how to load the whole site into a vector store yo that would be much appreciated. Thanks","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:25:28.738000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115828416453820477","type":0,"content":"<@529729093336563732> Word bro. Noobs helping noobs. Together we are mighty 🙂","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"529729093336563732","username":"lostAF","avatar":"23f0ad06b4743378129e1596a5e96a3a","discriminator":"1327","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:23:45.572000+00:00","edited_timestamp":"2023-06-07T02:24:03.288000+00:00","flags":0,"components":[]},{"id":"1115827809030512720","type":0,"content":"yea that worked! Thank you!","channel_id":"1038097349660135474","author":{"id":"529729093336563732","username":"lostAF","global_name":null,"avatar":"23f0ad06b4743378129e1596a5e96a3a","discriminator":"1327","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:21:20.751000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115826480761536552","type":0,"content":"<@529729093336563732> okay let me know how it goes","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"529729093336563732","username":"lostAF","avatar":"23f0ad06b4743378129e1596a5e96a3a","discriminator":"1327","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:16:04.067000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115823019915485294","type":0,"content":"I could do it that way, let me see if that works","channel_id":"1038097349660135474","author":{"id":"529729093336563732","username":"lostAF","global_name":null,"avatar":"23f0ad06b4743378129e1596a5e96a3a","discriminator":"1327","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:02:18.937000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115822907696877598","type":0,"content":"<@529729093336563732> Can you edit the llm variable that way before the call to the chain? Or does it need to happen in the chain call?","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"529729093336563732","username":"lostAF","avatar":"23f0ad06b4743378129e1596a5e96a3a","discriminator":"1327","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:01:52.182000+00:00","edited_timestamp":"2023-06-07T02:02:01.815000+00:00","flags":0,"components":[]},{"id":"1115822710019346493","type":0,"content":"llm.tempature = 0.9 might work","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T02:01:05.052000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115817170396516495","type":0,"content":"Is their a way to change the inference paramters when doing llm_chain.predict(input=prompt). Like I wanna change the temperature without having to do like a whole re creation of a model. Im using a custom LLM so I have the backend dealing with it","channel_id":"1038097349660135474","author":{"id":"529729093336563732","username":"lostAF","global_name":null,"avatar":"23f0ad06b4743378129e1596a5e96a3a","discriminator":"1327","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T01:39:04.303000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115815390468116633","type":0,"content":"I will upload my code for exporting the readthedocs site into a format that can be ingested into langchain. I will not abandon thee!!!! Who else needs","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T01:31:59.935000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115815132921073664","type":0,"content":"I am sorry but the readthedocs site doesn't even have a pdf download. Sketchy project designed for enterprises and uberdevelopers. Yep make hard to use on purpose to leave all us mere mortals behind. 😦 sigh","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-07T01:30:58.531000+00:00","edited_timestamp":"2023-06-07T01:31:18.513000+00:00","flags":0,"components":[]},{"id":"1115768775711658004","type":0,"content":"Solutions for pulling the langchain readthedocs into a vectorstore. The official solution uses wget but only returns a single index.html and ingests this. I need the whole site. Ideas yall?","channel_id":"1038097349660135474","author":{"id":"1099242406697762906","username":"doebird","global_name":null,"avatar":null,"discriminator":"6533","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T22:26:46.111000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115752416839749712","type":0,"content":"Is it possible to specify the schema to use with a postgre database?","channel_id":"1038097349660135474","author":{"id":"235135294070980608","username":"HelloThisIsASH","global_name":null,"avatar":"b93772a87fdbe5ae8360ef08e548ec85","discriminator":"3068","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T21:21:45.852000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115740110261071872","type":0,"content":"Has anyone tried to implement ElasticSearch where document level security is in play? I want to chat over documents but control ensure it can only access the documents it’s it has permissions to. Any help is appreciated","channel_id":"1038097349660135474","author":{"id":"826899160498044938","username":"Phil987","global_name":null,"avatar":null,"discriminator":"3836","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T20:32:51.735000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115727006156476538","type":0,"content":"can someone you explain the interplay of feeding chat_history in and setting a vector store memory?","channel_id":"1038097349660135474","author":{"id":"1059144367731920896","username":"LHC","global_name":null,"avatar":"ed1a726b431009a725e43eee977534db","discriminator":"1921","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T19:40:47.473000+00:00","edited_timestamp":"2023-06-06T19:40:59.555000+00:00","flags":0,"components":[]},{"id":"1115720556189339741","type":0,"content":"Hello 👋 \n\nI have the following custom agent defined\n\n```\nsql_tool = Tool(\n    name=\"Translate text-to-SQL for user data\",\n    description=(\n        \"Useful for looking up information about a particular persons: accounts, transactions, and other information.\"\n    ),\n    func=sql_chain.run,\n)\n\nlTools = load_tools([\"llm-math\"], llm=llm)\nfor tool in lTools:\n    tools.append(tool)\n\ntools.append(sql_tool)\n\nagent = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True,\n    max_iterations=25,\n)\n```\n\nWhen using this chain, I can never seem to get more than one iteration of the agent to run, even though there is a thought from the previous step.\n\n```\nObservation: The user's total savings is $295.07, and their monthly expenses are $12.76.\nThought:I need to determine if the user's savings and expenses are sufficient for retirement. I'll assume a 4% withdrawal rate and calculate the annual expenses.\n\n> Finished chain.\n```\n\nIs there a timeout or max token count stopping this from running further?","channel_id":"1038097349660135474","author":{"id":"319202288373596160","username":"vino","global_name":null,"avatar":"f5e9819a95099e0b4e7f145ef9157af8","discriminator":"5703","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T19:15:09.681000+00:00","edited_timestamp":"2023-06-06T19:15:43.929000+00:00","flags":0,"components":[]},{"id":"1115705582993817720","type":0,"content":"have anyone trained their own embedding model?\nDo you have any insights on it?","channel_id":"1038097349660135474","author":{"id":"297684182656745472","username":"erinnnn","global_name":null,"avatar":"b88705383fcfe174e1bcd9cffbc95be6","discriminator":"0488","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T18:15:39.793000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115703598244970526","type":0,"content":"maybe someone can help me. how i can catch exception in output parser? i have a problem when my app raise OutputParserException client has internal server error.","channel_id":"1038097349660135474","author":{"id":"693345491303530526","username":"bashenov","global_name":null,"avatar":"0ef91afdc8268f27fdba6e5305fbe05a","discriminator":"6040","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T18:07:46.592000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115693641596412105","type":0,"content":"could use some advice / sanity check!\nbuilding basically chatgpt as a chrome extension, and want to allow users to ask questions about any website they are on.\nsmall websites im using openai api and thats fine.\nlarger websites (beyond context window) I need to solve\n\nhow to quickly and cheaply handle larger websites? I've already tried chunking, but got hit with context too large error. I want to handle ideally in one request and not store anything long term since users will ask a question and move onto another website\n\nthanks!","channel_id":"1038097349660135474","author":{"id":"839112848168845382","username":"baltazar 🐉🐉","global_name":null,"avatar":"b07d37cb02ee80598e3c85210efce7cf","discriminator":"7599","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T17:28:12.742000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115685369896251563","type":0,"content":"Anybody using Azure? What abstraction are you using to use the embeddings?","channel_id":"1038097349660135474","author":{"id":"100821635820429312","username":"ryanglambert","global_name":null,"avatar":null,"discriminator":"9301","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T16:55:20.615000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115684034199175368","type":19,"content":"I am getting the following error: langchain.schema.OutputParserException: Could not parse LLM output:","channel_id":"1038097349660135474","author":{"id":"733138404040114188","username":"TomasMChess","global_name":null,"avatar":null,"discriminator":"9123","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T16:50:02.160000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115666916548280372"},"referenced_message":{"id":"1115666916548280372","type":0,"content":"Does anyone know how to use \"create_pandas_dataframe_agent\" using the GPT4All model?","channel_id":"1038097349660135474","author":{"id":"733138404040114188","username":"TomasMChess","global_name":null,"avatar":null,"discriminator":"9123","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T15:42:00.994000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1115666916548280372","type":0,"content":"Does anyone know how to use \"create_pandas_dataframe_agent\" using the GPT4All model?","channel_id":"1038097349660135474","author":{"id":"733138404040114188","username":"TomasMChess","global_name":null,"avatar":null,"discriminator":"9123","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T15:42:00.994000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115660151714758727","type":0,"content":"<@1072591948499664996>  How to change the output format of the SQLDatabaseChain ?\nIt returns the SQL Result in the form of string of dict , python.\nAnd is very difficult to parse client side.","channel_id":"1038097349660135474","author":{"id":"366287447446913035","username":"SK","global_name":null,"avatar":"266dc676908b2233258cd0c2c471fb73","discriminator":"7116","public_flags":64,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1072591948499664996","username":"kapa.ai","avatar":"09e7b0315ef53d57936eb7d461f40224","discriminator":"2237","public_flags":0,"flags":0,"bot":true,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T15:15:08.132000+00:00","edited_timestamp":null,"flags":32,"components":[],"thread":{"id":"1115660151714758727","guild_id":"1038097195422978059","parent_id":"1038097349660135474","owner_id":"1072591948499664996","type":11,"name":"How to change the output format of the SQLDatabaseChain ?It returns the SQL Result in the","last_message_id":"1115660595757318184","thread_metadata":{"archived":false,"archive_timestamp":"2023-06-06T15:15:08.356000+00:00","auto_archive_duration":1440,"locked":false,"create_timestamp":"2023-06-06T15:15:08.356000+00:00"},"message_count":7,"member_count":3,"rate_limit_per_user":0,"flags":0,"total_message_sent":7,"member_ids_preview":["366287447446913035","1072591948499664996","437808476106784770"]}},{"id":"1115656783256633344","type":0,"content":"I'm using Chroma's Persisted DB. I used a kaggle notebook to stuff the data into the db and was zipping it for use on my local pc so i can perform similarity search. It used to work at first but now there is some error occurring. I tried running it on a seperate kaggle notebook by uploading the db folder and then using it and it worked. Although using the same code did not work on my PC. \n\nThe error i'm getting is \"KeyError: 'elements'\" Although the same code is working on my kaggle notebooks","channel_id":"1038097349660135474","author":{"id":"152110504301690881","username":"ishaanshah812","global_name":null,"avatar":"9372d5ffaabdaae24e622527b21cbea1","discriminator":"7956","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T15:01:45.029000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115647852765511720","type":0,"content":"You can try chroma for free","channel_id":"1038097349660135474","author":{"id":"647512331416502295","username":"Klaudioz","global_name":null,"avatar":"1a98924251620e480f7ba8eca6b856ce","discriminator":"9243","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T14:26:15.834000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115642632178241566","type":0,"content":"What is the best vector store, for free? I was using Pinecone, but I feel is too expensive","channel_id":"1038097349660135474","author":{"id":"1078326467437531168","username":"jirpm","global_name":null,"avatar":null,"discriminator":"1547","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T14:05:31.149000+00:00","edited_timestamp":"2023-06-06T14:05:47.503000+00:00","flags":0,"components":[]},{"id":"1115621514784538675","type":0,"content":"<@1072591948499664996> is it possible to have async callbackhandlers","channel_id":"1038097349660135474","author":{"id":"568876245723643914","username":"foolishsailor","global_name":null,"avatar":"0e27c4833fe6d4f0fb7f49bfca5ad241","discriminator":"9138","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1072591948499664996","username":"kapa.ai","avatar":"09e7b0315ef53d57936eb7d461f40224","discriminator":"2237","public_flags":0,"flags":0,"bot":true,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T12:41:36.370000+00:00","edited_timestamp":null,"flags":32,"components":[],"thread":{"id":"1115621514784538675","guild_id":"1038097195422978059","parent_id":"1038097349660135474","owner_id":"1072591948499664996","type":11,"name":"is it possible to have async callbackhandlers","last_message_id":"1115639354803621900","thread_metadata":{"archived":false,"archive_timestamp":"2023-06-06T12:41:36.552000+00:00","auto_archive_duration":1440,"locked":false,"create_timestamp":"2023-06-06T12:41:36.552000+00:00"},"message_count":11,"member_count":3,"rate_limit_per_user":0,"flags":0,"total_message_sent":11,"member_ids_preview":["1072591948499664996","568876245723643914","437808476106784770"]}},{"id":"1115619557281910875","type":19,"content":"This is what it generates\n`\n\"text\": \"```json\\n{\\n    \\\"query\\\": \\\"\\\",\\n    \\\"filter\\\": \\\"gte(\\\\\\\"popularityScore\\\\\\\", 100)\\\"\\n}\\n```\",\n`","channel_id":"1038097349660135474","author":{"id":"374653296008495106","username":"fsa317","global_name":null,"avatar":"e947af00623b65886a4f0058b2c5eda2","discriminator":"7483","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T12:33:49.665000+00:00","edited_timestamp":"2023-06-06T12:34:01.393000+00:00","flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115618431107084378"},"referenced_message":{"id":"1115618431107084378","type":0,"content":"If I have documents that have metadata, like a score from 1-100, I notice my retreiver doesn't seem to understand how to sort by that field when I ask for the \"highest scored\", it will filter things if I explicitly say \"scores about 90\", but it doesn't seem to know how to sort.  Any tips?","channel_id":"1038097349660135474","author":{"id":"374653296008495106","username":"fsa317","global_name":null,"avatar":"e947af00623b65886a4f0058b2c5eda2","discriminator":"7483","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T12:29:21.164000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1115618431107084378","type":0,"content":"If I have documents that have metadata, like a score from 1-100, I notice my retreiver doesn't seem to understand how to sort by that field when I ask for the \"highest scored\", it will filter things if I explicitly say \"scores about 90\", but it doesn't seem to know how to sort.  Any tips?","channel_id":"1038097349660135474","author":{"id":"374653296008495106","username":"fsa317","global_name":null,"avatar":"e947af00623b65886a4f0058b2c5eda2","discriminator":"7483","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T12:29:21.164000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115592822192619590","type":19,"content":"`from langchain.llms.gpt4all import GPT4All` or `from langchain.llms import GPT4All`","channel_id":"1038097349660135474","author":{"id":"916275081519439872","username":"enric.rubio.reach","global_name":null,"avatar":null,"discriminator":"8584","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"132183241237987328","username":"adityasingh95","avatar":"cb0d22a931515fe59dec69f389b96b59","discriminator":"0","public_flags":576,"flags":576,"banner":null,"accent_color":null,"global_name":"adityasingh95","avatar_decoration":null,"display_name":"adityasingh95","banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T10:47:35.523000+00:00","edited_timestamp":"2023-06-06T12:39:19.220000+00:00","flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115589887018668052"},"referenced_message":{"id":"1115589887018668052","type":0,"content":"So I'm trying to run gpt4all.\n\nI'm doing \n\nfrom langchain.llms import gpt4all\n\nIt says cannot import. I've imported langchain, llama_index and specifically langchain.llms as well. It fails specifically for gpt4all. \n\nAny suggestions what to do?","channel_id":"1038097349660135474","author":{"id":"132183241237987328","username":"adityasingh95","global_name":"adityasingh95","avatar":"cb0d22a931515fe59dec69f389b96b59","discriminator":"0","public_flags":576,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T10:35:55.723000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1115590122885361816","type":0,"content":"Has anyone seen a project trying to give an LLM a docker sandbox environment to execute conatinerized apps?","channel_id":"1038097349660135474","author":{"id":"1059144367731920896","username":"LHC","global_name":null,"avatar":"ed1a726b431009a725e43eee977534db","discriminator":"1921","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T10:36:51.958000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115589972263710770","type":0,"content":"I'm running it on a Colab notebook","channel_id":"1038097349660135474","author":{"id":"132183241237987328","username":"adityasingh95","global_name":"adityasingh95","avatar":"cb0d22a931515fe59dec69f389b96b59","discriminator":"0","public_flags":576,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T10:36:16.047000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115589887018668052","type":0,"content":"So I'm trying to run gpt4all.\n\nI'm doing \n\nfrom langchain.llms import gpt4all\n\nIt says cannot import. I've imported langchain, llama_index and specifically langchain.llms as well. It fails specifically for gpt4all. \n\nAny suggestions what to do?","channel_id":"1038097349660135474","author":{"id":"132183241237987328","username":"adityasingh95","global_name":"adityasingh95","avatar":"cb0d22a931515fe59dec69f389b96b59","discriminator":"0","public_flags":576,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T10:35:55.723000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115588486045642822","type":0,"content":"Hello, I new to langchain and LLMs and I am having trouble connecting langchain/agent to bigquery. \n\nI have setup the agent using this snippet: \n```engine = create_engine(sqlalchemy_url)\ndb = SQLDatabase(engine=engine,\n                 include_tables=['2_transactions'])\n\ntoolkit = SQLDatabaseToolkit(db=db, llm=llm)\n\nsql_agent_executor = create_sql_agent(llm=llm,\n                                      toolkit=toolkit,\n                                      verbose=True)```\n\nWhen I tried running the question: \"How man rows are there?\" It doesn't use `2_transactions` as the table name, just `transactions`.\n\nIs there anyway to fix this (e.g. creating a custom prompt etc.)?  Any kind of help is much appreciated. Thanks.","channel_id":"1038097349660135474","author":{"id":"792782426006224906","username":"keyt","global_name":"k","avatar":"e916fd6219708654066ec40a423fd0d5","discriminator":"5843","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T10:30:21.705000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115586542849765466","type":0,"content":"Hey, How can I handle multiple requests at a time? do I need to use messaging queue? I am using Python...would appreciate any suggestions","channel_id":"1038097349660135474","author":{"id":"763712858432864276","username":"Vivek","global_name":null,"avatar":null,"discriminator":"8447","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T10:22:38.411000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115545251566866452","type":0,"content":"Hey guys, I need help with the memory when using the Chat Templates. I need to add messages to the prompt like this constantly:\n\n```\nrequest_previous_messages: List[BaseMessage] = [\n    HumanMessage(content=message.message)\n    if message.type == MessageType.HUMAN\n    else AIMessage(content=message.message)\n    for message in request.messages[:-1]\n]\n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        *request_previous_messages,\n        human_message_prompt,\n    ]\n)\n```\n\nDo you know how to use the `ConversationBufferMemory` to save the message's history and use them in every prompt? Or do I have to use the `PromptTemplate` for now?","channel_id":"1038097349660135474","author":{"id":"431995933295902740","username":"royalcrist","global_name":null,"avatar":"79219b4d7e1cfb5315386505fe2272fc","discriminator":"4303","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T07:38:33.802000+00:00","edited_timestamp":"2023-06-06T07:41:02.037000+00:00","flags":0,"components":[]},{"id":"1115543686630088765","type":19,"content":"Hi, you can define a Custom MultiAgent Actions like in this section:\nhttps://python.langchain.com/en/latest/modules/agents/agents/custom_multi_action_agent.html#custom-multiaction-agent\n\nFor the python action tool, you could create a tool for that:\nhttps://python.langchain.com/en/latest/modules/agents/tools/custom_tools.html#defining-custom-tools\n\nIn the `def plan`, you can define multiple agents to run. You can create two: the first one with only the LLM, and the second one with the LLM + the tool.","channel_id":"1038097349660135474","author":{"id":"431995933295902740","username":"royalcrist","global_name":null,"avatar":"79219b4d7e1cfb5315386505fe2272fc","discriminator":"4303","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"244182157013155851","username":"BuahahaXD","avatar":"e9b0cf9b9bde2666416cdf785f99a190","discriminator":"2920","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T07:32:20.692000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115532225254006826"},"referenced_message":{"id":"1115532225254006826","type":0,"content":"Hi, Im struggling with an issue. I have a Python application that runs a prompt which returns a JSON object. Then I want to extract certain elements from JSON (without LLMs, simply in Python) and pass it as an input to another prompt. I would like to use SequentialChain but I have no idea how to chain LLMChain -> Custom Python operation -> LLMChain. Can you give me some tips what I should use? Thanks a lot","channel_id":"1038097349660135474","author":{"id":"244182157013155851","username":"BuahahaXD","global_name":null,"avatar":"e9b0cf9b9bde2666416cdf785f99a190","discriminator":"2920","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T06:46:48.087000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1115532225254006826","type":0,"content":"Hi, Im struggling with an issue. I have a Python application that runs a prompt which returns a JSON object. Then I want to extract certain elements from JSON (without LLMs, simply in Python) and pass it as an input to another prompt. I would like to use SequentialChain but I have no idea how to chain LLMChain -> Custom Python operation -> LLMChain. Can you give me some tips what I should use? Thanks a lot","channel_id":"1038097349660135474","author":{"id":"244182157013155851","username":"BuahahaXD","global_name":null,"avatar":"e9b0cf9b9bde2666416cdf785f99a190","discriminator":"2920","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T06:46:48.087000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115531847976357908","type":0,"content":"Python or JS? I'm building a chatbot with the plan to embed it in a website. Is there a strong latency performance and user experience difference by having it built in JS over Python (excl. the differences in integrations and features)? I'd be more comfortable with Python but I understand that the JS implementation is better for the web","channel_id":"1038097349660135474","author":{"id":"819166255474147338","username":"oryx","global_name":null,"avatar":null,"discriminator":"4702","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-06T06:45:18.137000+00:00","edited_timestamp":"2023-06-06T06:45:52.664000+00:00","flags":0,"components":[]},{"id":"1115402171836538880","type":0,"content":"I created a very simple gradio + langchain integration. It asks user to upload a file, and lets user ask a question about the file. But the return value I get from Langchain always seems to be \"I don't know.\" It was working a couple of hours ago but not anymore. Is there something I’m doing wrong here? The code is so simple, and I think it was working just fine…\n\nThis is my code: https://pastebin.com/raw/fc4zdL0X","channel_id":"1038097349660135474","author":{"id":"761217073455038484","username":"ksp99","global_name":null,"avatar":null,"discriminator":"4284","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T22:10:00.936000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115400222273712159","type":0,"content":"Hello guys,\n\nI am newbie using LangChain, so sorry for my newbies questions.\nI am using this code:\n\ntemplate = \"\"\"\nCurrent conversation:\n{history}\nHuman: {input}\nAI Assistant:\"\"\"\nPROMPT = PromptTemplate(\ninput_variables=[\"history\", \"input\"], template=template\n)\n\nllm = ChatOpenAI(temperature=0.6)\nconversation = ConversationChain(\nllm=llm, verbose=False, prompt=PROMPT, memory=ConversationSummaryBufferMemory(\nllm=llm,\nmax_token_limit=1024\n))\nconversation.predict(input=\"Hello\")\n\n\n\nIs my code correct for sending prompts in the ConversationChain object? What is the difference between passing the Template to ConversationSummaryBufferMemory and ConversationChain?\n\nDoes my code work with Summary? Does it summarize the conversation? (This is related with the first question)\n\nI need to create an API that works like the ChatGPT platform. What is the best way to store/retrieve the entire conversation? I need to maintain the calls made to this API.\n\nThank you so much,","channel_id":"1038097349660135474","author":{"id":"364053051008614401","username":"Gustavo","global_name":null,"avatar":null,"discriminator":"9862","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T22:02:16.124000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115393131723104406","type":19,"content":"my python version is 3.10.9 and langchain version is 0.0.190","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T21:34:05.605000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115393009090035786"},"referenced_message":{"id":"1115393009090035786","type":0,"content":"I need help. My code works fine when I prompts but when I import langchain and pass ChatOpenAI(), I get a validationError saying it did not find the key.  Meanwhile, the api key is provided.","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T21:33:36.367000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1115393009090035786","type":0,"content":"I need help. My code works fine when I prompts but when I import langchain and pass ChatOpenAI(), I get a validationError saying it did not find the key.  Meanwhile, the api key is provided.","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T21:33:36.367000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115378150982029433","type":0,"content":"Hello, how can you pass linting process ? Even when I clone the current master branch and run 'make lint', many errors still occur.","channel_id":"1038097349660135474","author":{"id":"993125671738036314","username":"Berke Dilekoğlu","global_name":null,"avatar":"239d4e618a5b6070ed4b50594ccc8dd0","discriminator":"0962","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T20:34:33.918000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115360121615286366","type":0,"content":"Dear Support,\n\nIt seems that LangChain has a limit of words asigned to aprox 120, when you try to ask about a embbeding text, in the following fashion:\n`\nqa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY), chain_type=\"stuff\", retriever=vectordb.as_retriever())\nanswer = qa.run(question)\n`\nThe answer will be always truncated to 120 words aprox. \nHow can I overcome this limitation?\n\nThanks","channel_id":"1038097349660135474","author":{"id":"283668277333590017","username":"dawveed","global_name":null,"avatar":"ced1d45ac216dc2607f3e76130cea1a7","discriminator":"3804","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T19:22:55.382000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115359637076717638","type":0,"content":"Hello, question about custom LLM wrappers in Langchain. Are there any examples of what this should look like? The documentation here: https://python.langchain.com/en/latest/modules/models/llms/examples/custom_llm.html shows that you only need to implement the _call method, however it's not clear to me how the run_manager parmeter should be used without looking at the Langchain code itself. Is there any documentation on that parameter?","channel_id":"1038097349660135474","author":{"id":"680534106849017856","username":"mjparrott","global_name":null,"avatar":"3c3672e5878bbe1c44f09dc1a55ad92c","discriminator":"0647","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T19:20:59.859000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115356226528759962","type":0,"content":"Hello\nI'm using JSONLoader on my Mac Os, and I hit the following error \n\nfrom langchain.document_loaders import JSONLoader\n\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\nCell In[1], line 1\n----> 1 from langchain.document_loaders import JSONLoader\n\nImportError: cannot import name 'JSONLoader' from 'langchain.document_loaders' (/Users/xxxxxxxxxxxxxxx/anaconda3/lib/python3.10/site-packages/langchain/document_loaders/__init__.py)\n\nAny pointers on how to resolve this?","channel_id":"1038097349660135474","author":{"id":"948231961611218984","username":"guru","global_name":null,"avatar":null,"discriminator":"1613","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T19:07:26.721000+00:00","edited_timestamp":"2023-06-05T19:07:38.355000+00:00","flags":0,"components":[]},{"id":"1115347449318477834","type":0,"content":"Any way to pass FakeEmbeddings to Chroma.from_texts ?\n\nI'm getting ```ValueError: Number of documents 1 must match number of ids 4``` errors","channel_id":"1038097349660135474","author":{"id":"339028113067606016","username":"discordm","global_name":null,"avatar":null,"discriminator":"6410","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T18:32:34.071000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115345933740277840","type":0,"content":"What am I doing wrong here \"  const executor = await initializeAgentExecutorWithOptions(tools, model, {\n    agentType: \"chat-zero-shot-react-description\",\n    verbose: true,\n    max_iterations: 2,\n    early_stopping_method: \"generate\"\n  });\n\"","channel_id":"1038097349660135474","author":{"id":"1092642636285870161","username":"ribbontorque","global_name":null,"avatar":"dd6d748bb2e63b73598e4421c018a348","discriminator":"2076","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T18:26:32.729000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115344909889703947","type":0,"content":"I think the JS Lang Chain Docs are down... I'm trying to find out how to Cap Max iterations in my typescript agent","channel_id":"1038097349660135474","author":{"id":"1092642636285870161","username":"ribbontorque","global_name":null,"avatar":"dd6d748bb2e63b73598e4421c018a348","discriminator":"2076","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T18:22:28.624000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115344816218316870","type":0,"content":"https://js.langchain.com/docs/modules/agents/exector","channel_id":"1038097349660135474","author":{"id":"1092642636285870161","username":"ribbontorque","global_name":null,"avatar":"dd6d748bb2e63b73598e4421c018a348","discriminator":"2076","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T18:22:06.291000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115343284152311858","type":19,"content":"https://status.openai.com/","channel_id":"1038097349660135474","author":{"id":"1092642636285870161","username":"ribbontorque","global_name":null,"avatar":"dd6d748bb2e63b73598e4421c018a348","discriminator":"2076","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[{"type":"link","url":"https://status.openai.com/","title":"OpenAI Status","description":"Welcome to OpenAI's home for real-time and historical data on system performance.","reference_id":"1115343284152311858"}],"mentions":[{"id":"1114863089897177129","username":"Warren_K","avatar":null,"discriminator":"3958","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T18:16:01.018000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115334138468241469"},"referenced_message":{"id":"1115334138468241469","type":0,"content":"Is chat gpt having api problems today?","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T17:39:40.517000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1115343153017401496","type":0,"content":"How do you guys manage max iterations? I've been hitting that problem a lot recently... Is it just an issue with how my prompt is crafted?","channel_id":"1038097349660135474","author":{"id":"1092642636285870161","username":"ribbontorque","global_name":null,"avatar":"dd6d748bb2e63b73598e4421c018a348","discriminator":"2076","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T18:15:29.753000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115334138468241469","type":0,"content":"Is chat gpt having api problems today?","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T17:39:40.517000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115327360825298944","type":0,"content":"How can I ignore symbols with PyPDFLoader?. I have some big PDFs with images so I'm interested only in the text.","channel_id":"1038097349660135474","author":{"id":"647512331416502295","username":"Klaudioz","global_name":null,"avatar":"1a98924251620e480f7ba8eca6b856ce","discriminator":"9243","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T17:12:44.601000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115323890852438080","type":0,"content":"ey i have a langchain api with FastApi and i deployed in EC2 AWS for just call with GET and POST request. But, i have error with the CORS when i run in my web app. Whats the recommended way to deploy an api ?","channel_id":"1038097349660135474","author":{"id":"592812102733791253","username":"Ger Godfrey","global_name":null,"avatar":"59f17934cdd6cfeaa0f6a60dc7d54b21","discriminator":"0264","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T16:58:57.295000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115319986639097926","type":0,"content":"I have chat api key setup in my jupyter notebook.. when i prompt it, I get output but when I import Langchain and call chatOpenAI(temperature=0.0). I get a validation error... api key not found..... Any help?","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T16:43:26.458000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115301308233171044","type":0,"content":"Hi we are building google matching engine index and end point .. what is the best retriever for this vector store?","channel_id":"1038097349660135474","author":{"id":"895727668744585216","username":"rams","global_name":null,"avatar":null,"discriminator":"0128","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T15:29:13.179000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115300643909935164","type":0,"content":"In a JSON loader how do set the schema to all fields?","channel_id":"1038097349660135474","author":{"id":"374653296008495106","username":"fsa317","global_name":null,"avatar":"e947af00623b65886a4f0058b2c5eda2","discriminator":"7483","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T15:26:34.792000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115293880573755422","type":0,"content":"Whats the recommended way to define an output schema for a nested json, the method I use doesn't feel ideal. \n\n```\n# adding to planner -> from langchain.experimental.plan_and_execute import load_chat_planner\n\nrefinement_response_schemas = [\n        ResponseSchema(name=\"plan\", description=\"\"\"{'1': {'step': '','tools': [],'data_sources': [],'sub_steps_needed': bool},\n '2': {'step': '','tools': [<empty list>],'data_sources': [<>], 'sub_steps_needed': bool},}\"\"\"),] #define json schema in description, works but doesn't feel proper\n    \nrefinement_output_parser = StructuredOutputParser.from_response_schemas(refinement_response_schemas)\nrefinement_format_instructions = refinement_output_parser.get_format_instructions()\n\nrefinement_output_parser.parse(output)```\n\ngives:\n\n```{'plan': {'1': {'step': 'Identify the top 5 strikers in La Liga',\n   'tools': [],\n   'data_sources': ['sports websites', 'official league statistics'],\n   'sub_steps_needed': False},\n  '2': {'step': 'Identify the top 5 strikers in the Premier League',\n   'tools': [],\n   'data_sources': ['sports websites', 'official league statistics'],\n   'sub_steps_needed': False},\n    ...\n  '6': {'step': 'Given the above steps taken, please respond to the users original question',\n   'tools': [],\n   'data_sources': [],\n   'sub_steps_needed': False}}}```\n\n\nit works but I want to know if theres a better way to go about this.","channel_id":"1038097349660135474","author":{"id":"1058035792431288460","username":"Nas","global_name":null,"avatar":"9ae02501bd59d855f024bb880b1d5f4c","discriminator":"0875","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T14:59:42.287000+00:00","edited_timestamp":"2023-06-05T15:07:52.711000+00:00","flags":0,"components":[]},{"id":"1115291289613766676","type":0,"content":"you can only input  4127 tokens into that llm, your inputs are too big","channel_id":"1038097349660135474","author":{"id":"485597060867948545","username":"ThePersonOfFun","global_name":null,"avatar":"fb754394710bbc3598cc65b19babeef8","discriminator":"2631","public_flags":128,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T14:49:24.554000+00:00","edited_timestamp":"2023-06-05T14:49:32.877000+00:00","flags":0,"components":[]},{"id":"1115290980082532453","type":0,"content":"While I am doing example of babyAGI I meet error of max token. \n\nhttps://python.langchain.com/en/latest/use_cases/autonomous_agents/baby_agi.html\n\nAnyone know how to solve this ?","channel_id":"1038097349660135474","author":{"id":"437475708399255562","username":"OPCT Dev - Jay","global_name":null,"avatar":"1db77eb27deccacb94c8c9a38c199cfd","discriminator":"0709","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1115290980145430578","filename":"Screenshot_2023-06-05_at_11.48.05_PM.png","size":187470,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1115290980145430578/Screenshot_2023-06-05_at_11.48.05_PM.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1115290980145430578/Screenshot_2023-06-05_at_11.48.05_PM.png","width":2524,"height":544,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T14:48:10.756000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115284904079527996","type":0,"content":"When using tools, can I have a variety of action names for one action, my llm gets close but no cigar?","channel_id":"1038097349660135474","author":{"id":"485597060867948545","username":"ThePersonOfFun","global_name":null,"avatar":"fb754394710bbc3598cc65b19babeef8","discriminator":"2631","public_flags":128,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T14:24:02.124000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115270450205966376","type":0,"content":"Hey I defined this custom tool:\n\ndesc = (\n    \"use this tool to fetch a public company's latest SEC filing in html form, given its CIK number (ex. for Apple NASDAQ:AAPL, 302193) \"\n    \"To use the tool you must provide the following parameter \"\n    \"['cik'].\"\n)\n\nclass FetchTool(BaseTool):\n    name = \"Fetch Latest Filing\"\n    description = desc\n\n    def _run(\n        self,\n        cik = None\n    ):\n        # check for the values we have been given\n        print(\"Running FetchTool\")\n        if cik:\n            return fetch_html(fetch_latest_10k(cik))\n        else:\n            return \"No CIK Provided\"\n    \n    def _arun(self, query: str):\n        raise NotImplementedError(\"This tool does not support async\")\n\ntools = [FetchTool()]\n\n\nbut i keep getting this tool not valid error\n\n> Entering new AgentExecutor chain...\n```json\n{\n    \"action\": \"Fetch Latest Filing\",\n    \"action_input\": {\n        \"cik\": \"0000320193\"\n    }\n}\n```\nObservation: Fetch Latest Filing is not a valid tool, try another one.\nThought:I apologize for the confusion earlier. Here is the response to your original question:\n\n```json\n{\n    \"action\": \"Fetch Latest Filing\",\n    \"action_input\": {\n        \"cik\": \"0000320193\"\n    }\n}\n``` \n\nThis will fetch the latest SEC filing for Apple in HTML format, which should contain the information you are looking for.\nObservation: Fetch Latest Filing is not a valid tool, try another one.","channel_id":"1038097349660135474","author":{"id":"1093688077391777864","username":"finvisual support","global_name":null,"avatar":"f1b05c647cff3016d8e5472ad11a8fa9","discriminator":"1887","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T13:26:36.052000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115261448873050223","type":0,"content":"Vinay Namani — Today at 6:18 PM\nHow to control this seq_len from langchain?\n\nAssertionError: Cannot forward input with seq_len=2325, this model only supports seq_len<=2048","channel_id":"1038097349660135474","author":{"id":"860175526558826517","username":"Vinay Namani","global_name":null,"avatar":"fc8ba771a2252310702bdfa68394e903","discriminator":"8144","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T12:50:49.967000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115249956635295764","type":0,"content":"[Help]: How can I fix this issue?\nHello everyone! As a chatbot developer, I am currently building a chatbot using LangChain and it has been amazing so far. Unfortunately, I have encountered a critical issue. Even though I trained the model with new data, the chatbot still provides answers using old data. How can I fix this? Is it possible to resolve this issue by upgrading the prompt? If not, how can I fix it? If you have already experienced this issue and have a solution, please let me know. Thank you!","channel_id":"1038097349660135474","author":{"id":"940675440048242778","username":"Apollo12","global_name":null,"avatar":"eca1557d6154de225eae59ff1844c8d7","discriminator":"4018","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T12:05:10.004000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115249693019099187","type":0,"content":"How can I use langchain to build a tool to write technical documentation with just a few inputs for my product?\nIf not possible, is there a way to convert a video into technical documentation? or vice versa? Like step by step guide with video.","channel_id":"1038097349660135474","author":{"id":"705315990602383430","username":"therakeshpurohit","global_name":"Rakesh Purohit","avatar":"591a68c5acbece681520b3c6f57bfdf1","discriminator":"4210","public_flags":64,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T12:04:07.153000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115232453225873419","type":0,"content":"Hey there. I have created vector embedding of my documents and stored them using Chroma. Is it possible to retrieve an embedding of a single document from there?\n```\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nsave_directory = \"db\"\n\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\ndocuments = text_splitter.create_documents(multiple_abstracts,\n                                           metadatas= multiple_metadata\n                                          )\n\n\n\ndb = Chroma.from_documents(documents = documents,\n                           embedding= embeddings,\n                           persist_directory=save_directory\n                          )\n\ndb.persist()\n\ndb.get()\n```\nWhen I use `db.get` it outputs a json with IDs and documents themselves. however, I do not see their vector embedding. How can I get this ?","channel_id":"1038097349660135474","author":{"id":"301114343322550274","username":"QWERTY","global_name":null,"avatar":"04eaad71c58303bf4677c4ccc597e8f5","discriminator":"8948","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T10:55:36.866000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115225280404017252","type":0,"content":"Hey guys i'm looking for some help:\n\nI have a basic chatbot that takes a pdf and uses conversationretrivalchain to query the data in the documents. I'm looking for a way to make the Chatbot more talkative/proactive. Right now its just giving my answer. I want to make it more like a human. \n\nHere is the code for the bot :\n\nqa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), db.as_retriever())\nresult = qa({\"question\": query, \"chat_history\": chat_history})\nchat_history.append((query, result['answer']))\n\nI've seen some stuff about using templates but i'm not sure how to go about doing this. Can anyone with more experience please help me.","channel_id":"1038097349660135474","author":{"id":"358935632682156033","username":"DoubleAs","global_name":null,"avatar":"e2b7efbcef7e12f64f698865816bacad","discriminator":"0437","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T10:27:06.732000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115205789351694357","type":0,"content":"Hi guys, why I can't access the  AzureBlobStorageContainerLoader  from 'langchain/document_loaders' ?\nIt says 'AzureBlobStorageContainerLoader' is declared but its value is never read\nModule '\"langchain/document_loaders\"' has no exported member 'AzureBlobStorageContainerLoader'? Anyone? Appreciate your help.","channel_id":"1038097349660135474","author":{"id":"531030875798765568","username":"kevinbaroro","global_name":null,"avatar":"eef00ea809f1d7a58e4f8cc315f65a71","discriminator":"3055","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T09:09:39.703000+00:00","edited_timestamp":"2023-06-05T09:10:04.931000+00:00","flags":0,"components":[]},{"id":"1115203957980135474","type":0,"content":"Hello guys. I have an issue with counting tokens in sequential chains. It pretty well specified for total calculation (using get_openai_callback as well as cb.total_tokens and etc) however I cannot figure out how to count tokens for each chain in sequential chains. Do you have any idea how can I do this?","channel_id":"1038097349660135474","author":{"id":"576375428630183956","username":"furi","global_name":null,"avatar":null,"discriminator":"6714","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T09:02:23.070000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115197426496716822","type":0,"content":"im setting the combine prompt - but its returning 4 results of the combine","channel_id":"1038097349660135474","author":{"id":"813569862273204245","username":"OG","global_name":null,"avatar":"e9676f83ef6814f4ebb5f141b63729fa","discriminator":"5657","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T08:36:25.843000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115196963068059678","type":0,"content":"does anyone know why a map reduce summarization chain would return outputs of what looks like 4 prompts from 6 documents?","channel_id":"1038097349660135474","author":{"id":"813569862273204245","username":"OG","global_name":null,"avatar":"e9676f83ef6814f4ebb5f141b63729fa","discriminator":"5657","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T08:34:35.353000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115194356597534721","type":19,"content":"prompt it to ask more if the input is vague","channel_id":"1038097349660135474","author":{"id":"813569862273204245","username":"OG","global_name":null,"avatar":"e9676f83ef6814f4ebb5f141b63729fa","discriminator":"5657","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"745516430023327744","username":"Conner_Kenway","avatar":"cd52029530a1072d52d367b8d231d865","discriminator":"8212","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T08:24:13.922000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1115183583590613162"},"referenced_message":{"id":"1115183583590613162","type":19,"content":"Hi guys, can anyone help me with this?","channel_id":"1038097349660135474","author":{"id":"745516430023327744","username":"Conner_Kenway","global_name":null,"avatar":"cd52029530a1072d52d367b8d231d865","discriminator":"8212","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T07:41:25.437000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114816125688094830"}}},{"id":"1115193952501514321","type":0,"content":"what might be the reason that 'PlanAndExecuteAgentExecutor' runs for a long time, appearing hung? the Joe Biden age example took me 3 minutes to run (update: now 5 mins), is it normal? what are some tips to prevent the plan making from taking long time ?\nupdate: it seems that the planner is stuck in a loop. it may eventually get out after several minutes, but most of the time it appears doing the same thing. is this a #bug ?\n```\n[llm/start] [1:llm:openai] Entering LLM run with input: {...}\n[llm/end] [1:llm:openai] [16.89s] Exiting LLM run with output: {...}\n[llm/start] [1:llm:openai] Entering LLM run with input: {...}\n[llm/end] [1:llm:openai] [16.89s] Exiting LLM run with output: {...}\n[llm/start] [1:llm:openai] Entering LLM run with input: {...}\n[llm/end] [1:llm:openai] [16.89s] Exiting LLM run with output: {...}\n.\n.\n.\n```","channel_id":"1038097349660135474","author":{"id":"1115190197517299742","username":"lorusacro","global_name":null,"avatar":null,"discriminator":"3753","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T08:22:37.578000+00:00","edited_timestamp":"2023-06-05T09:11:08.569000+00:00","flags":0,"components":[]},{"id":"1115183583590613162","type":19,"content":"Hi guys, can anyone help me with this?","channel_id":"1038097349660135474","author":{"id":"745516430023327744","username":"Conner_Kenway","global_name":null,"avatar":"cd52029530a1072d52d367b8d231d865","discriminator":"8212","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T07:41:25.437000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114816125688094830"},"referenced_message":{"id":"1114816125688094830","type":0,"content":"Hi Community,\n\nI wanted to know if there is a way to generate responses by asking users for more specific details related to the generic question they asked. For example, in the image below, I simply typed \"Python,\" but Chat-GPT smartly responded by asking for more specific questions or topics we would like to discuss regarding Python.\n\nI'm curious if LangChain offers any specific methods for implementing such capabilities in our chatbot. Could you please provide some insights?","channel_id":"1038097349660135474","author":{"id":"745516430023327744","username":"Conner_Kenway","global_name":null,"avatar":"cd52029530a1072d52d367b8d231d865","discriminator":"8212","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1114816125792956426","filename":"0.png","size":11702,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1114816125792956426/0.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1114816125792956426/0.png","width":854,"height":191,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T07:21:16.646000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1115171149228298280","type":0,"content":"Hello IS there a way how to set up custom prompt for ConversationalRetrievalChain ?","channel_id":"1038097349660135474","author":{"id":"992809327817658459","username":"jake13","global_name":null,"avatar":"a3dfac015cdf2402dab695b795f5cbdd","discriminator":"9504","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T06:52:00.854000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115150600427028501","type":19,"content":"Here is the code snippet","channel_id":"1038097349660135474","author":{"id":"787705681574625310","username":"Skittle","global_name":null,"avatar":"e0c155503c4526f2d059bdfd9951ef5d","discriminator":"3972","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T05:30:21.638000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114790942503878686"},"referenced_message":{"id":"1114790942503878686","type":19,"content":"Here is the code snippet.\n```\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nloader = TextLoader(\"state_of_the_union.txt\")\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntexts = text_splitter.split_documents(documents)\n\nembeddings = OpenAIEmbeddings(chunk_size=1)\ndocsearch = Chroma.from_documents(texts, embeddings)\n\nqa = RetrievalQA.from_chain_type(llm=get_chat_model(), chain_type=\"stuff\", retriever=docsearch.as_retriever(), verbose = True)\n\nquery = \"What did the president say about Chuck Schumer?\"\nqa.run(query)\n```","channel_id":"1038097349660135474","author":{"id":"787705681574625310","username":"Skittle","global_name":null,"avatar":"e0c155503c4526f2d059bdfd9951ef5d","discriminator":"3972","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"482577614398029824","username":"aviran","avatar":null,"discriminator":"9815","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T05:41:12.507000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114649643981230181"}}},{"id":"1115150538493939773","type":19,"content":"Can someone help me with this please?","channel_id":"1038097349660135474","author":{"id":"787705681574625310","username":"Skittle","global_name":null,"avatar":"e0c155503c4526f2d059bdfd9951ef5d","discriminator":"3972","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T05:30:06.872000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114647816371966083"},"referenced_message":{"id":"1114647816371966083","type":0,"content":"Hello, I am not getting any intermediate outputs for retrievalQA even though I have set the verbose = True. Can someone help me please?","channel_id":"1038097349660135474","author":{"id":"787705681574625310","username":"Skittle","global_name":null,"avatar":"e0c155503c4526f2d059bdfd9951ef5d","discriminator":"3972","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1114647816426508288","filename":"Screenshot_2023-06-04_014202.png","size":8139,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1114647816426508288/Screenshot_2023-06-04_014202.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1114647816426508288/Screenshot_2023-06-04_014202.png","width":558,"height":144,"content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-03T20:12:28.578000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1115148946705236039","type":0,"content":"could someone please help me out with vectorstore w/chromadb and retrival, i want to use my own llm & embedding instead of openai","channel_id":"1038097349660135474","author":{"id":"532724989217079296","username":"AverageSciStudent","global_name":"Barrel Of Lube","avatar":"a_f550ecaee00faee00ac5e6b63726b708","discriminator":"7954","public_flags":128,"avatar_decoration":"v3_a_23309e19e3396c5e0b15583caf969417"},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T05:23:47.360000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115146447034265642","type":0,"content":"How do you guys manage max iterations? I've been hitting that problem a lot recently... Is it just an issue with how my prompt is crafted?","channel_id":"1038097349660135474","author":{"id":"1092642636285870161","username":"ribbontorque","global_name":null,"avatar":"dd6d748bb2e63b73598e4421c018a348","discriminator":"2076","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T05:13:51.392000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115110533599854634","type":0,"content":"Hello! I am looking to draw insights across multiple pdfs. Any good ways other than converting pdfs and a couple retrieval plus summary langchains?\n\nI have seen RetrievaQAx, Document compressor, document transformer from langchain","channel_id":"1038097349660135474","author":{"id":"515371328317161479","username":"devilsadvocate","global_name":null,"avatar":null,"discriminator":"3199","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T02:51:08.962000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115107009780514818","type":0,"content":"anyone has a good example how to send/receive the streamed result of ChatOpenAI in js? (best case with sveltekit endpoints)","channel_id":"1038097349660135474","author":{"id":"1008913832569225360","username":"SimonNom","global_name":null,"avatar":"4cca81dceefe73fba68033d2e6d31fe1","discriminator":"5220","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T02:37:08.818000+00:00","edited_timestamp":"2023-06-05T02:38:47.521000+00:00","flags":0,"components":[]},{"id":"1115088185106628718","type":19,"content":"Everything should work fine if you have latest packages installed. First use miniconda and not anaconda. This way you will have a light weight conda env and you can add on to it as you want.","channel_id":"1038097349660135474","author":{"id":"780667203967254529","username":"btisback","global_name":null,"avatar":"c1140d00a052cf98d2ccd22cdc5ad6bf","discriminator":"5898","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1114863089897177129","username":"Warren_K","avatar":null,"discriminator":"3958","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T01:22:20.666000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114954268445786225"},"referenced_message":{"id":"1114954268445786225","type":0,"content":"I tried upgrading but it is taking forever on their site....","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T16:30:12.446000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1115082626122919946","type":0,"content":"Hei there, I am digging into langchain and after a lot of hazzle, I am starting to understand what is embedding and vectorstores. I have a question, I am using huggingface embeddings, a tutorial showed to use intfloat_e5-large-v2 as its the best ranking one, but I get theis message: \n\"No sentence-transformers model found with name C:\\Users... ...\\sentence_transformers\\intfloat_e5-large-v2. Creating a new one with MEAN pooling.\"\nI don't know what this means exactly, but feels as if is not using that model and defaulting to the so called MEAN pooling? \nI could successfully query the database afterwards, so I am not sure if  I should keep wondering about what model to use as I literally dont know what difference makes","channel_id":"1038097349660135474","author":{"id":"342557093213110284","username":"Carlosmk","global_name":null,"avatar":"f6072e2dc1833bcd7aa2f6373579ceb5","discriminator":"8600","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-05T01:00:15.301000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1115029111509876907","type":0,"content":"Has anyone tried the ArxivLoader yet? I'm having trouble ingesting an entire paper using the ArxivLoader that is part of langchain. It only ever ingests the title/authors/abstract but does not ingest the rest of the paper.","channel_id":"1038097349660135474","author":{"id":"135678591638831104","username":"purplepill3m","global_name":null,"avatar":"692e6ecf04257d819ad50e306b547e74","discriminator":"4879","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T21:27:36.423000+00:00","edited_timestamp":"2023-06-04T21:27:53.420000+00:00","flags":0,"components":[]},{"id":"1114997137915265056","type":19,"content":"I think I found a potential cause of the repeated answers. I played around replacing GPT4All and the sBERT models with corresponding OpenAI models.\nMy conclusion from that is: whenever I select to use any of the GPT4All models, then the RetrievalQA run() response repeats exactly three times. So either it's the LangChain wrapper of the GPT4All models or the GPT4All Python model binding itself that is causing the issue.\nIf I were to take a guess, then I expect the issue in the LangChain wrapper, since the GPT4All chat application itself (meaning all the models) have no issue at all.\nI will do further research on that in the coming days, when I find a few hours of spare time.\nIf anyone else has specific evidence on what could be the cause, that would be highly appreciated!!!","channel_id":"1038097349660135474","author":{"id":"1111604177278345277","username":"CRJ-SB","global_name":null,"avatar":null,"discriminator":"3025","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T19:20:33.324000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114840142063075448"},"referenced_message":{"id":"1114840142063075448","type":0,"content":"Hello all, I created a chatbot for a semantic search of local pdf documents. I am running everything locally because the docs contain IP of the company I work for. So I am using ChromaDB, SentenceTransformer for embeddings, one of the LLMs from GPT4All, and the RetrievalQA chain. \nEverything works fine except that answer I receive when I run(query) is repeated multiple times. To be precise the answer is given 3 times. What could be the cause of this?","channel_id":"1038097349660135474","author":{"id":"1111604177278345277","username":"CRJ-SB","global_name":null,"avatar":null,"discriminator":"3025","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T08:56:42.596000+00:00","edited_timestamp":"2023-06-04T08:57:45.314000+00:00","flags":0,"components":[]}},{"id":"1114973690275307561","type":0,"content":"```\nloader = TextLoader(\"state_of_the_union.txt\")\ndocument = loader.load()\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"])\ndocs = text_splitter.split_documents(document)\n\n\nfrom langchain import embeddings\nfrom langchain.embeddings import LlamaCppEmbeddings\nllama_embedds = LlamaCppEmbeddings(model_path=\"./WizardLM-7B-uncensored.ggmlv3.q4_0.bin\")\nembedding = llama_embedds\ndb = FAISS.from_documents(docs, embedding)\n```\nThis takes a long time and I can't tell if it is frozen?","channel_id":"1038097349660135474","author":{"id":"485597060867948545","username":"ThePersonOfFun","global_name":null,"avatar":"fb754394710bbc3598cc65b19babeef8","discriminator":"2631","public_flags":128,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T17:47:22.971000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1114954268445786225","type":0,"content":"I tried upgrading but it is taking forever on their site....","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T16:30:12.446000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1114953809874133113","type":19,"content":"Thank you. I am new here, and I want to learn a lot from you. But, is it possible for me to uninstall anaconda navigator and reinstall it to fix or update the current Python version?","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"324173358147174401","username":"CodeGriot","avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T16:28:23.114000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114951720288665693"},"referenced_message":{"id":"1114951720288665693","type":19,"content":"Right, so you're also running an old version of pip, I guess that matches the Python. I don't use Windows or Anaconda, so I might be at a dead end in terms of helping, sorry. Maybe someone else here can help figure out why you're stuck on such old versions of everything.","channel_id":"1038097349660135474","author":{"id":"324173358147174401","username":"CodeGriot","global_name":null,"avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1114863089897177129","username":"Warren_K","avatar":null,"discriminator":"3958","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T16:20:04.918000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114944043919614064"}}},{"id":"1114951720288665693","type":19,"content":"Right, so you're also running an old version of pip, I guess that matches the Python. I don't use Windows or Anaconda, so I might be at a dead end in terms of helping, sorry. Maybe someone else here can help figure out why you're stuck on such old versions of everything.","channel_id":"1038097349660135474","author":{"id":"324173358147174401","username":"CodeGriot","global_name":null,"avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"1114863089897177129","username":"Warren_K","avatar":null,"discriminator":"3958","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T16:20:04.918000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114944043919614064"},"referenced_message":{"id":"1114944043919614064","type":19,"content":"","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1114944044309676092","filename":"Screenshot_20230604_034808.png","size":89709,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1114944044309676092/Screenshot_20230604_034808.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1114944044309676092/Screenshot_20230604_034808.png","width":752,"height":209,"content_type":"image/png"}],"embeds":[],"mentions":[{"id":"324173358147174401","username":"CodeGriot","avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T15:49:34.729000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114937797267181609"}}},{"id":"1114945227510255698","type":0,"content":"```python\nfrom langchain.embeddings import LlamaCppEmbeddings\nllama = LlamaCppEmbeddings(model_path=\"./WizardLM-7B-uncensored.ggmlv3.q4_0.bin\")\ntext = \"This is a test document.\"\nquery_result = llama.embed_query(text)\ndoc_result = llama.embed_documents([text])\n\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n``` now what?, I am also able to run normal Lang chain pipes with llama models, how do I know add docs to it???","channel_id":"1038097349660135474","author":{"id":"485597060867948545","username":"ThePersonOfFun","global_name":null,"avatar":"fb754394710bbc3598cc65b19babeef8","discriminator":"2631","public_flags":128,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T15:54:16.919000+00:00","edited_timestamp":"2023-06-04T16:06:18.424000+00:00","flags":0,"components":[]},{"id":"1114944345183879238","type":0,"content":"","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1114944345238409357","filename":"Screenshot_20230604_034853.png","size":232315,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1114944345238409357/Screenshot_20230604_034853.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1114944345238409357/Screenshot_20230604_034853.png","width":800,"height":340,"description":"I tried using this command and this is what i got","content_type":"image/png"}],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T15:50:46.556000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1114944043919614064","type":19,"content":"","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[{"id":"1114944044309676092","filename":"Screenshot_20230604_034808.png","size":89709,"url":"https://cdn.discordapp.com/attachments/1038097349660135474/1114944044309676092/Screenshot_20230604_034808.png","proxy_url":"https://media.discordapp.net/attachments/1038097349660135474/1114944044309676092/Screenshot_20230604_034808.png","width":752,"height":209,"content_type":"image/png"}],"embeds":[],"mentions":[{"id":"324173358147174401","username":"CodeGriot","avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T15:49:34.729000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114937797267181609"},"referenced_message":{"id":"1114937797267181609","type":0,"content":"You must not be using something UNIX-like. OK just\n```\npip install --dry-run langchain\n```\nBut just look at the first few lines (which should mention langchain & give a version)","channel_id":"1038097349660135474","author":{"id":"324173358147174401","username":"CodeGriot","global_name":null,"avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T15:24:45.411000+00:00","edited_timestamp":null,"flags":0,"components":[]}},{"id":"1114937797267181609","type":0,"content":"You must not be using something UNIX-like. OK just\n```\npip install --dry-run langchain\n```\nBut just look at the first few lines (which should mention langchain & give a version)","channel_id":"1038097349660135474","author":{"id":"324173358147174401","username":"CodeGriot","global_name":null,"avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T15:24:45.411000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1114937383897538610","type":19,"content":"head is not recognised as an internal  or external command","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"324173358147174401","username":"CodeGriot","avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T15:23:06.856000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114917304719921191"},"referenced_message":{"id":"1114917304719921191","type":0,"content":"What do you see if you run:\n```\npip install --dry-run langchain | head\n```","channel_id":"1038097349660135474","author":{"id":"324173358147174401","username":"CodeGriot","global_name":null,"avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T14:03:19.607000+00:00","edited_timestamp":"2023-06-04T14:14:09.377000+00:00","flags":0,"components":[]}},{"id":"1114933016888872980","type":0,"content":"const resp = await PineconeStore.fromDocuments(docs, embeddings, {\n        pineconeIndex: index,\n        namespace: 'rns',\n        textKey: 'text',\n    })","channel_id":"1038097349660135474","author":{"id":"813569862273204245","username":"OG","global_name":null,"avatar":"e9676f83ef6814f4ebb5f141b63729fa","discriminator":"5657","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T15:05:45.680000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1114933008114389033","type":0,"content":"yooo - im using this function to store vectore in pinecone. is there a way i can get the resulting vectors to use again later in my code?","channel_id":"1038097349660135474","author":{"id":"813569862273204245","username":"OG","global_name":null,"avatar":"e9676f83ef6814f4ebb5f141b63729fa","discriminator":"5657","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T15:05:43.588000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1114917304719921191","type":0,"content":"What do you see if you run:\n```\npip install --dry-run langchain | head\n```","channel_id":"1038097349660135474","author":{"id":"324173358147174401","username":"CodeGriot","global_name":null,"avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T14:03:19.607000+00:00","edited_timestamp":"2023-06-04T14:14:09.377000+00:00","flags":0,"components":[]},{"id":"1114916307121487983","type":0,"content":"Hmm. Something weird is going on. I'm getting a bunch of replayed messages","channel_id":"1038097349660135474","author":{"id":"324173358147174401","username":"CodeGriot","global_name":null,"avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T13:59:21.761000+00:00","edited_timestamp":null,"flags":0,"components":[]},{"id":"1114909888951357441","type":19,"content":"Even when I use upgrade langchain in my environments I still get LC 0.0.27","channel_id":"1038097349660135474","author":{"id":"1114863089897177129","username":"Warren_K","global_name":null,"avatar":null,"discriminator":"3958","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[{"id":"324173358147174401","username":"CodeGriot","avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"flags":0,"banner":null,"accent_color":null,"global_name":null,"avatar_decoration":null,"display_name":null,"banner_color":null}],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T13:33:51.550000+00:00","edited_timestamp":null,"flags":0,"components":[],"message_reference":{"channel_id":"1038097349660135474","guild_id":"1038097195422978059","message_id":"1114907993755090974"},"referenced_message":{"id":"1114907993755090974","type":0,"content":"Oh hang on, you're using a super old version of LC. I don't know if that still applies, but I also suspect you'll struggle to get help with such an old version","channel_id":"1038097349660135474","author":{"id":"324173358147174401","username":"CodeGriot","global_name":null,"avatar":"9ab8739bdac478bec41b10f8caf766be","discriminator":"6758","public_flags":0,"avatar_decoration":null},"attachments":[],"embeds":[],"mentions":[],"mention_roles":[],"pinned":false,"mention_everyone":false,"tts":false,"timestamp":"2023-06-04T13:26:19.700000+00:00","edited_timestamp":null,"flags":0,"components":[]}}]